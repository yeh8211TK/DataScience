{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 資料預處理\n",
    "\n",
    "#### 資料預處理流程:\n",
    "\n",
    "**遺失值處理(missing data)** $\\rightarrow$ 資料轉換(transform) $\\rightarrow$ 異常值處理(outlier) $\\rightarrow$ 資料縮放(scaling)\n",
    "\n",
    "### 遺失值(missing data)處理\n",
    "\n",
    "#### 1. 為什麼存在遺失值?\n",
    "\n",
    "- 真實世界的資料為雜亂的資料(messy data)\n",
    "\n",
    "- 數值在資料獲取過程中遺失\n",
    "\n",
    "- 數值意外地被刪除\n",
    "\n",
    "\n",
    "#### 2. 為什麼要處理遺失值?\n",
    "\n",
    "- 適當的處理遺失值可以降低引進誤差(bias)的機率\n",
    "\n",
    "- 大部分 ML 演算法需要完整的資料\n",
    "\n",
    "\n",
    "#### 3. 遺失值的處理流程\n",
    "\n",
    "(1) 偵測所有的遺失值\n",
    "\n",
    "(2) 轉換所有遺失值為 NaN 值\n",
    "\n",
    "(3) 分析遺失值的數量和型態 (數值、時間序列、種類)\n",
    "\n",
    "(4) 適當地刪除或填補遺失值\n",
    "\n",
    "(5) 評估和比較資料處理過後的表現\n",
    "\n",
    "\n",
    "#### 4. Null 值運算比較 (None v.s. np.nan)\n",
    "\n",
    "(1) 邏輯運算:\n",
    "\n",
    "- None: None or True/False $\\Rightarrow$ True/False\n",
    "\n",
    "- np.nan: np.nan or True/False $\\Rightarrow$ nan\n",
    "\n",
    "(2) 四則運算:\n",
    "\n",
    "- None + True (For all operators) $\\Rightarrow$ TypeError: unsupported operand\n",
    "\n",
    "- np.nan * True (For all operators) $\\Rightarrow$ nan\n",
    "\n",
    "(3) 型態: type()\n",
    "\n",
    "- type(None) $\\Rightarrow$ NoneType\n",
    "\n",
    "- type(np.nan) $\\Rightarrow$ float\n",
    "\n",
    "(4) 比較運算:\n",
    "\n",
    "- None == None $\\Rightarrow$ True\n",
    "\n",
    "- np.nan == np.nan $\\Rightarrow$ False\n",
    "\n",
    "(5) np.isnan()\n",
    "\n",
    "- np.isnan(None) $\\Rightarrow$ False\n",
    "\n",
    "- np.isnan(np.nan) $\\Rightarrow$ True\n",
    "\n",
    "\n",
    "#### 5. 偵測與取代遺失值\n",
    "\n",
    "(1) 偵測遺失值: \n",
    "\n",
    "- character: \"NA\", \"-\", \".\"\n",
    "\n",
    "\n",
    "- inherent missing values within the data like '0'\n",
    "\n",
    "\n",
    "Example:\n",
    "\n",
    "    df = pd.read_csv('data.csv')\n",
    "\n",
    "    df.head()\n",
    "\n",
    "    df.info()\n",
    "\n",
    "    df_unique = df.csat.unique()\n",
    "    np.sort(df_unique)\n",
    "\n",
    "\n",
    "(2) 使用 NaN 取代遺失值:\n",
    "\n",
    "a. '.' $\\Rightarrow$ 'NaN'\n",
    "\n",
    "Example:\n",
    "\n",
    "    df = pd.read_csv('data.csv', na_values='.')\n",
    "\n",
    "b. '0' $\\Rightarrow$ 'NaN'\n",
    "\n",
    "Example:\n",
    "\n",
    "    df = pd.read_csv(\"data.csv')\n",
    "\n",
    "    df.col[df.col == 0] = np.nan\n",
    "\n",
    "    df.col[np.isnan(df.col)]\n",
    "    \n",
    "    \n",
    "#### 6.  計算遺失值的數量\n",
    "\n",
    "Example:\n",
    "\n",
    "    df = pd.read_csv('data.csv', parse_dates=['Date'], index_col='Date')\n",
    "    \n",
    "    df.head()\n",
    "\n",
    "\n",
    "(1) Nullity DataFrame: 使用 df.isnull() 或 df.isna() 的方法\n",
    "\n",
    "    df_nullity = df.isnull()\n",
    "    \n",
    "    df_nullity.head()\n",
    "\n",
    "\n",
    "(2) 遺失值總量\n",
    "\n",
    "    df_nullity.sum()\n",
    "\n",
    "\n",
    "(3) 遺失值佔所有資料的百分比\n",
    "\n",
    "    df_nullity.mean() * 100\n",
    "\n",
    "\n",
    "(4) Missingno package: 遺失值圖形化分析的套件\n",
    "\n",
    "    import missingno as msno\n",
    "\n",
    "- Nullity Bar: \n",
    "\n",
    "      msno.bar(df)\n",
    "\n",
    "\n",
    "- Nullity Matrix: \n",
    "\n",
    "      msno.matrix(df)\n",
    "\n",
    "\n",
    "- Nullity Matrix for time-series data: \n",
    "\n",
    "      msno.matrix(df, freq='M')\n",
    "\n",
    "\n",
    "- Fine tuning the matrix: \n",
    "\n",
    "      msno.matrix(df.loc['start-date': 'end-date'], freq='M')\n",
    "\n",
    "\n",
    "#### 7. 遺失值的型態\n",
    "\n",
    "(1) 不同遺失值型態產生的原因\n",
    "\n",
    "[Note] variable: data field or column in a DataFrame\n",
    "\n",
    "- Values simply missing at random instances or intervals in a variable\n",
    "\n",
    "\n",
    "- Values missing due to another variable\n",
    "\n",
    "\n",
    "- Values missing due to the missingness of the same or another variable\n",
    "\n",
    "\n",
    "(2) missingness 的型態\n",
    "\n",
    "a. Missing Completely at Random (MCAR)\n",
    "\n",
    "定義: Missingness has no relationship between any values, observed or missing.\n",
    "\n",
    "b. Missing at Random (MAR): \n",
    "\n",
    "定義: There is a systematic relationship between missingness and other observed data, but not the missing data.\n",
    "\n",
    "c. Missing Not at Random (MNAR): \n",
    "\n",
    "定義: There is a relationship between missingness and its values, missing or non-missing.\n",
    "\n",
    "\n",
    "(3) 找出 missingness 之間的關係並分類\n",
    "\n",
    "a. 排序變數值\n",
    "\n",
    "    sorted = df.sort_values('col_name')\n",
    " \n",
    "    msno.matrix(sorted)\n",
    "\n",
    "\n",
    "b. Missingness heatmap or correlation map\n",
    "\n",
    "    msno.heatmap(df)\n",
    "   \n",
    "   \n",
    "- 圖形化欄位之間遺失值的相關性(correlation)\n",
    "\n",
    "\n",
    "- 解釋欄位之間 missingness 的相依性\n",
    "\n",
    "\n",
    "c. Missingness dendrogram\n",
    "\n",
    "    msno.dendrogram(df)\n",
    "    \n",
    "    \n",
    "- 以樹狀圖呈現 missingness\n",
    "\n",
    "\n",
    "- 藉由分群變數來描述變數之間的關係\n",
    "\n",
    "\n",
    "#### 8. 視覺化不同變數間的 missingness\n",
    "\n",
    "Example:\n",
    "    \n",
    "    def fill_dummy_values(df, scaling_factor):\n",
    "        # Create copy of dataframe\n",
    "        df_dummy = df.copy(deep=True)\n",
    "\n",
    "        # Iterate over each column\n",
    "        for col in df_dummy:\n",
    "      \n",
    "            # Get column, column missing values and range\n",
    "            col = df_dummy[col]\n",
    "            col_null = col.isnull()\n",
    "            num_nulls = col_null.sum()\n",
    "            col_range = col.max() - col.min()\n",
    "\n",
    "            # Shift and scale dummy values\n",
    "            dummy_values = (rand(num_nulls) - 2)\n",
    "            dummy_values = dummy_values * scaling_factor * col_range + col.min()\n",
    "\n",
    "            # Return dummy values\n",
    "            col[col_null] = dummy_values\n",
    "\n",
    "        return df_dummy\n",
    "\n",
    "    # Create dummy dataframe\n",
    "    df_dummy = fill_dummy_values(df)\n",
    "\n",
    "    # Get missing values of both columns for coloring\n",
    "    nullity = df.col1.isnull() + df.col2.isnull()\n",
    "\n",
    "    # Generate scatter plot\n",
    "    df_dummy.plot(x='col1', y='col2', kind='scatter', alpha=0.5, c=nullity, cmap='rainbow')\n",
    "\n",
    "\n",
    "#### 9. 刪除/省略(Omission)遺失值\n",
    "\n",
    "(1) 刪除/省略(Omission)遺失值的條件\n",
    "\n",
    "- 當遺失值的型態為 MCAR\n",
    "\n",
    "\n",
    "(2) 刪除/省略(Omission)的方法\n",
    "\n",
    "a. Pairwise deletion: 去除欄位有 NaN 的資料\n",
    "\n",
    "Example 1: 去除所有含有遺失值的行\n",
    "\n",
    "    df.dropna(axis=1)\n",
    "    \n",
    "\n",
    "Example 2: 計算平均值\n",
    "\n",
    "    df['col'].mean() = df['col'].sum() / df['col'].count()\n",
    "\n",
    "\n",
    "b. Listwise deletion: 去除整筆資料 \n",
    "\n",
    "Example 1: 去除所有含有遺失值的列\n",
    "\n",
    "    df.dropna(axis=0)\n",
    "\n",
    "\n",
    "Example 2: 去除特定欄位含有遺失值的列\n",
    "\n",
    "    df.dropna(subset=['col'], how='any', inplace=True)\n",
    "\n",
    "    msno.matrix(df)\n",
    "\n",
    "\n",
    "參數說明:\n",
    "\n",
    "(i) how : {‘any’, ‘all’}, default ‘any’\n",
    "\n",
    "- ‘any’ : If any NA values are present, drop that row or column.\n",
    "\n",
    "- ‘all’ : If all values are NA, drop that row or column.\n",
    "\n",
    "\n",
    "(ii) inplace : bool, default False\n",
    "\n",
    "- If True, do operation inplace and return None.\n",
    "\n",
    "\n",
    "#### 10. 基本的補值(imputation)方法與視覺化\n",
    "\n",
    "(1) 平均數填補\n",
    "\n",
    "    from sklearn.impute import SimpleImputer\n",
    "\n",
    "    df_mean = df.copy(deep=True)\n",
    "    \n",
    "    mean_imputer = SimpleImputer(strategy='mean')\n",
    "    \n",
    "    df_mean.iloc[ : , : ] = mean_imputer.fit_transform(df_mean)\n",
    "\n",
    "\n",
    "(2) 中位數填補\n",
    "\n",
    "    df_median = df.copy(deep=True)\n",
    "\n",
    "    median_imputer = SimpleImputer(strategy='median')\n",
    "    \n",
    "    df_median.iloc[ : , : ] = median_imputer.fit_transform(df_median)\n",
    "\n",
    "\n",
    "(3) 眾數填補\n",
    "\n",
    "    df_mode = df.copy(deep=True)\n",
    "\n",
    "    mode_imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "    df_mode.iloc[ : , : ] = mode_imputer.fit_transform(df_mode)\n",
    "\n",
    "\n",
    "(4) 常數填補\n",
    "\n",
    "a. 使用 SimpleImputer() 函式\n",
    "\n",
    "    df_constant = df.copy(deep=True)\n",
    "\n",
    "    constant_imputer = SimpleImputer(strategy='constant', fill_value=0)\n",
    "\n",
    "    df_constant.iloc[ : , : ] = constant_imputer.fit_transform(df_constant)\n",
    "\n",
    "\n",
    "b. 使用 .fillna()\n",
    "\n",
    "    df_filled = df.fillna(0)\n",
    "\n",
    "\n",
    "(5) 迭代填補(Iterative imputation)\n",
    "\n",
    "    from sklearn.experimental import enable_iterative_imputer\n",
    "    from sklearn.impute import IterativeImputer\n",
    "\n",
    "    # Subset numeric features: numeric_cols [字串欄位: df.select_dtypes(include = ['object'] )]\n",
    "    numeric_cols = df.select_dtypes(include = [np.number])\n",
    " \n",
    "    # Iteratively impute\n",
    "    imp_iter = IterativeImputer(max_iter=5, sample_posterior=True, random_state=123)\n",
    "    df_imp_iter = imp_iter.fit_transform(numeric_cols)\n",
    "\n",
    "    # Convert returned array to DataFrame\n",
    "    df_imp_iterDF = pd.DataFrame(df_imp_iter, columns=numeric_cols.columns)\n",
    "\n",
    "    # Check the DataFrame's info\n",
    "    print(df_imp_iterDF.info())\n",
    "\n",
    "\n",
    "(6) 補值後的資料散佈圖(scatter plot)\n",
    "\n",
    "    nullity = df['col_1'].isnull() + df['col_2'].isnull()\n",
    "\n",
    "    df_mean.plot(x='col_1', y='col_2', kind='scatter', alpha=0.5, c=nullity, cmap='rainbow', title='Mean Imputation')\n",
    "\n",
    "\n",
    "(7) 視覺化各種補值方法\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(10, 10))\n",
    "\n",
    "    nullity = df['col_1'].isnull() + df['col_2'].isnull()\n",
    "    \n",
    "    imputations = {'Mean Imputation': df_mean,\n",
    "                   'Median Imputation': df_median,\n",
    "                   'Most Frequent Imputation': df_mode,\n",
    "                   'Constant Imputation': df_constant}\n",
    "\n",
    "    for ax, df_key in zip(axes.flatten(), imputations):\n",
    "    \n",
    "        imputations[df_key].plot(x='col_1', y='col_2', kind='scatter', alpha=0.5, c=nullity, cmap='rainbow', ax=ax, colorbar=False, title=df_key)\n",
    "\n",
    "\n",
    "(8) 各種刪除/省略(Omission)/填補方法對資料的影響:\n",
    "\n",
    "- 刪除/省略(Omission): 可能移除大量的資料\n",
    "\n",
    "\n",
    "- 以常數 0 填補: 誤差下降\n",
    "\n",
    "\n",
    "- 平均數填補: 資料中異常值(outliers)的多寡會影響平均數的大小\n",
    "\n",
    "\n",
    "- 中位數填補: 較適合處理異常值(outliers)存在的情況\n",
    "\n",
    "\n",
    "- 眾數&迭代填補: 資料根據不同的情況會有不同程度的影響\n",
    "\n",
    "\n",
    "#### 11. 時間序列資料的補值(imputation)與視覺化\n",
    "\n",
    "(1) .fillna() method\n",
    "\n",
    "a. Ffill/pad method\n",
    "\n",
    "- Replace NaNs with last observed value\n",
    "\n",
    "      df.fillna(method='ffill', inplace=True)\n",
    "\n",
    "b. Bfill/backwardfill method\n",
    "\n",
    "- Replace NaNs with next observed value\n",
    "\n",
    "      df.fillna(method='bfill', inplace=True)\n",
    "\n",
    "(2) .interpolate() method\n",
    "\n",
    "a. Linear interpolation: Impute linearly or with equidistant values\n",
    "\n",
    "    linear_interp = df.interpolate(method='linear', inplace=True)\n",
    "\n",
    "b. Quadratic interpolation: Impute the values quadratically\n",
    "\n",
    "    quadratic_interp = df.interpolate(method='quadratic', inplace=True)\n",
    "\n",
    "c. Nearest value imputation: Impute with the nearest observable value\n",
    "\n",
    "    nearest_interp = df.interpolate(method='nearest', inplace=True)\n",
    "\n",
    "(3) Visualizing imputations \n",
    "\n",
    "Example: A comparison of the interpolations\n",
    "\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(30, 20))\n",
    "\n",
    "    interpolations = {'Linear Interpolation': linear_interp,\n",
    "                      'Quadratic Interpolation': quadratic_interp,\n",
    "                      'Nearest Interpolation': nearest_interp}\n",
    "\n",
    "    for ax, df_key in zip(axes, interpolations):\n",
    "    \n",
    "        interpolations[df_key].col.plot(color='red', marker='o', linestyle='dotted', ax=ax)\n",
    "        \n",
    "        df['col'].plot(title=df_key + ' - col', marker='o', ax=ax)\n",
    "        \n",
    "        \n",
    "#### 12. 使用 fancyimpute 套件補值 (A variety of matrix completion and imputation algorithms)\n",
    "\n",
    "(1) fancyimpute 套件\n",
    "\n",
    "- 套件包含進階的填補技術\n",
    "\n",
    "\n",
    "- 使用機械學習演算法(KNN)填補遺失值\n",
    "\n",
    "\n",
    "- 使用其他的欄位特徵預測並填補遺失值(MICE)\n",
    "\n",
    "\n",
    "(2) fancyimpute 填補技術\n",
    "\n",
    "a. K-Nearest Neighbor (KNN)\n",
    "\n",
    "- Select K nearest or similar data points using all the non-missing features\n",
    "\n",
    "\n",
    "- Take average of the selected data points to fill in the missing feature\n",
    "\n",
    "      \n",
    "      from fancyimpute import KNN\n",
    "\n",
    "      knn_imputer = KNN()\n",
    "\n",
    "      df_knn = df.copy(deep=True)\n",
    "      \n",
    "      df_knn.iloc[ : , : ] = knn_imputer.fit_transform(df_knn)\n",
    "\n",
    "\n",
    "b. Multiple Imputation by Chained Equations (MICE)\n",
    "\n",
    "- Perform multiple regressions over random sample of the data\n",
    "\n",
    "\n",
    "- Take average of the multiple regression values\n",
    "\n",
    "\n",
    "- Impute the missing feature value for the data point\n",
    "\n",
    "\n",
    "- MICE is a very robust model for imputation\n",
    "\n",
    "\n",
    "      from fancyimpute import IterativeImputer\n",
    "\n",
    "      MICE_imputer = IterativeImputer()\n",
    "\n",
    "      df_MICE = df.copy(deep=True)\n",
    "\n",
    "      df_MICE.iloc[ : , : ] = MICE_imputer.fit_transform(df_MICE)\n",
    "      \n",
    "      \n",
    "#### 13. 填補種類值\n",
    "\n",
    "(1) 種類值的複雜性(Complexity)\n",
    "\n",
    "- 大多數的種類值為字串，不能對字串做運算\n",
    "\n",
    "\n",
    "- 種類值必須從字串轉換到數值再填補\n",
    "\n",
    "\n",
    "(2) 種類值的轉換方法\n",
    "\n",
    "- one-hot encoder\n",
    "\n",
    "\n",
    "- ordinal encoder\n",
    "\n",
    "\n",
    "(3) 種類值的填補\n",
    "\n",
    "- 以出現頻率最高的種類作填補\n",
    "\n",
    "\n",
    "- 使用統計模型作填補(如: KNN)\n",
    "\n",
    "\n",
    "(4) 填補種類值的步驟 (以 ordinal encoder 為例)\n",
    "\n",
    "i. 將無遺失值的種類欄位轉換成 ordinal values\n",
    "\n",
    "\n",
    "ii. 在 ordinal DataFrame 填補遺失值\n",
    "\n",
    "\n",
    "iii. 將 ordinal values 轉換回種類值\n",
    "\n",
    "\n",
    "**Step 1: Ordinal encoder**\n",
    "\n",
    "    from sklearn.preprocessing import OrdinalEncoder\n",
    "    \n",
    "    # Create dictionary for Ordinal encoders\n",
    "    ordinal_enc_dict = {}\n",
    "\n",
    "    # Loop over columns to encode\n",
    "    for col_name in df:\n",
    "    \n",
    "        # Create ordinal encoder for the column\n",
    "        ordinal_enc_dict[col_name] = OrdinalEncoder()\n",
    "\n",
    "        # Select the non-null values in the column\n",
    "        col = df[col_name] \n",
    "        col_not_null = col[col.notnull()]\n",
    "        reshaped_vals = col_not_null.values.reshape(-1, 1)\n",
    "\n",
    "        # Encode the non-null values of the column\n",
    "        encoded_vals = ordinal_enc_dict[col_name].fit_transform(reshaped_vals)\n",
    "\n",
    "        # Replace the column with ordinal values\n",
    "        df.loc[col.notnull(), 'col_name'] = np.squeeze(encoded_vals)\n",
    "      \n",
    "**Step 2: 使用 KNN 填補**\n",
    "\n",
    "    df_KNN_imputed = df.copy(deep=True)\n",
    "\n",
    "    # Create MICE imputer\n",
    "    KNN_imputer = KNN()\n",
    "\n",
    "    df_KNN_imputed.iloc[ : , : ] = np.round(KNN_imputer.fit_transform(df))\n",
    "\n",
    "**Step 3: Ordinal decoder**\n",
    "\n",
    "    for col_name in users:\n",
    "        reshaped_col = df[col_name].values.reshape(-1, 1) \n",
    "        df_KNN_imputed[col_name] = ordinal_enc_dict[col_name].inverse_transform(reshaped_col)\n",
    "\n",
    "\n",
    "#### 14. 評估不同的填補方法\n",
    "\n",
    "(1) 為何要評估?\n",
    "\n",
    "- 填補可以用來改進模型的表現\n",
    "\n",
    "\n",
    "- 選擇能讓機械學習模型的表現為最佳的填補方法\n",
    "\n",
    "\n",
    "- Density plots 能解釋了資料的分佈\n",
    "\n",
    "\n",
    "- 可以作為檢查填補方法差異的度量\n",
    "\n",
    "\n",
    "(2) 擬合線性模型並求出統計量\n",
    "\n",
    "    import statsmodels.api as sm\n",
    "\n",
    "    df_cc = df.dropna(how='any')\n",
    "\n",
    "    X = sm.add_constant(df_cc.iloc[ : , :-1])\n",
    "\n",
    "    y = df_cc['Class']\n",
    "\n",
    "    lm = sm.OLS(y, X).fit()\n",
    "\n",
    "    print(lm.summary())\n",
    "\n",
    "\n",
    "R-squared 與 Coefficients:\n",
    "\n",
    "- lm.rsquared_adj\n",
    "\n",
    "\n",
    "- lm.params\n",
    "\n",
    "\n",
    "(3) 評估與比較不同填補方法的步驟\n",
    "\n",
    "i. 在 statsmodels 套件中使用線性模型\n",
    "\n",
    "\n",
    "ii. 比較 coefficients 和 standard errors\n",
    "\n",
    "\n",
    "iii. 比較 density plots\n",
    "\n",
    "Example:\n",
    "\n",
    "a. Fit linear model on different imputed DataFrames\n",
    "\n",
    "    # Mean Imputation\n",
    "    X = sm.add_constant(df_mean_imputed.iloc[:, :-1])\n",
    "    y = df['Class']\n",
    "    lm_mean = sm.OLS(y, X).fit()\n",
    "\n",
    "    # KNN Imputation\n",
    "    X = sm.add_constant(df_knn_imputed.iloc[:, :-1])\n",
    "    lm_KNN = sm.OLS(y, X).fit()\n",
    "\n",
    "    # MICE Imputation\n",
    "    X = sm.add_constant(df_mice_imputed.iloc[:, :-1])\n",
    "    lm_MICE = sm.OLS(y, X).fit()\n",
    "\n",
    "b. Comparing R-squared of different imputations\n",
    "\n",
    "    print(pd.DataFrame({'Complete': lm.rsquared_adj,\n",
    "                        'Mean Imp.': lm_mean.rsquared_adj,\n",
    "                        'KNN Imp.': lm_KNN.rsquared_adj,\n",
    "                        'MICE Imp.': lm_MICE.rsquared_adj},\n",
    "                         index=['R_squared_adj']))\n",
    "\n",
    "c. Comparing coefficients of different imputations\n",
    "\n",
    "    print(pd.DataFrame({'Complete': lm.params,\n",
    "                        'Mean Imp.': lm_mean.params,\n",
    "                        'KNN Imp.': lm_KNN.params,\n",
    "                        'MICE Imp.': lm_MICE.params}))\n",
    "\n",
    "d. Comparing density plots\n",
    "\n",
    "    df_cc['A'].plot(kind='kde', c='red', linewidth=3)\n",
    "    df_mean_imputed['A'].plot(kind='kde')\n",
    "    df_knn_imputed['A'].plot(kind='kde')\n",
    "    df_mice_imputed['A'].plot(kind='kde')\n",
    "\n",
    "    labels = ['Baseline (Complete Case)', 'Mean Imputation', 'KNN Imputation', 'MICE Imputation']\n",
    " \n",
    "    plt.legend(labels)\n",
    "    plt.xlabel('A')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
