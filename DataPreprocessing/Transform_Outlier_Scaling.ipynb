{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 資料預處理\n",
    "\n",
    "#### 資料預處理流程:\n",
    "\n",
    "遺失值處理(missing data) $\\rightarrow$ **資料轉換(transform)** $\\rightarrow$ **異常值處理(outlier)** $\\rightarrow$ **資料縮放(scaling)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 資料轉換(transform)\n",
    "\n",
    "#### 1. 資料轉換(Data transformation)的目的\n",
    "\n",
    "- 減少異常值(outlier)的影響\n",
    "\n",
    "\n",
    "- 使資料近似常態分佈\n",
    "\n",
    "\n",
    "#### 2. Log transformation\n",
    "\n",
    "(1) Captures relative changes, the magnitude of change, and keeps everything in the positive space.\n",
    "\n",
    "(2) Log normalization using numpy\n",
    "\n",
    "a. Checking the variance\n",
    "\n",
    "    print(df[\"col\"].var())\n",
    "\n",
    "b. Apply the log normalization function to the column\n",
    "\n",
    "    df[\"col\"] = np.log(df[\"col\"])\n",
    "\n",
    "c. Check the variance of the normalized column\n",
    "\n",
    "    print(df[\"col\"].var())\n",
    "    \n",
    "#### 3. Box-Cox transformation\n",
    "\n",
    "(1) A way to transform non-normal dependent variables into a normal shape\n",
    "\n",
    "\n",
    "(2) Scipy 套件:\n",
    "\n",
    "      scipy.stats.boxcox(data, lmbda=p)\n",
    "\n",
    "- p = -2: reciprocal square\n",
    "\n",
    "\n",
    "- p = -1: reciprocal\n",
    "\n",
    "\n",
    "- p = -0.5: reciprocal square root\n",
    "\n",
    "\n",
    "- p = 0: log\n",
    "\n",
    "\n",
    "- p = 0.5: square root\n",
    "\n",
    "\n",
    "- p = 1: no transform\n",
    "\n",
    "\n",
    "- p = 2: square\n",
    "\n",
    "\n",
    "Example: 資料轉換(Data transformation)\n",
    "       \n",
    "    # Subset data\n",
    "    A = data['A']\n",
    "\n",
    "    # Histogram and kernel density estimate\n",
    "    plt.figure()\n",
    "    sns.distplot(A)\n",
    "    plt.show()\n",
    "\n",
    "    # Box-Cox transformation\n",
    "    A_log = boxcox(A, lmbda=0)\n",
    "\n",
    "    # Histogram and kernel density estimate\n",
    "    plt.figure()\n",
    "    sns.distplot(A_log)\n",
    "    plt.show()\n",
    "\n",
    "#### 4. 若資料轉換後，仍存在異常值(outlier)\n",
    "\n",
    "$\\Rightarrow$ 執行異常值(outlier)處理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 異常值(Outlier)的偵測與處理方法\n",
    "\n",
    "#### 1. 異常值(Outlier)圖形視覺化\n",
    "\n",
    "(1) boxplot conditioned on target variable\n",
    "\n",
    "    sns.boxplot() \n",
    "\n",
    "Example: 使用 boxplots 觀察異常值(outlier)\n",
    "    \n",
    "    # Import modules\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2)\n",
    "    \n",
    "    # Univariate boxplot\n",
    "    sns.boxplot(y=data['B'], ax=ax[0])\n",
    "    \n",
    "    # Multivariate boxplot\n",
    "    sns.boxplot(x='A', y='B', data=data, ax=ax[1])\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "(2) histogram and kernel density estimate (kde)\n",
    "\n",
    "    sns.distplot()\n",
    "\n",
    "#### 2. 異常值(Outlier)處理方法\n",
    "\n",
    "(1) Z-score 處理異常值(outliers)\n",
    "\n",
    "- Z-score gives a threshold for outliers approximately +/-3 standard deviations away from the mean.\n",
    "\n",
    "\n",
    "- Z-scores are often used for scaling the data prior to creating a model.\n",
    "\n",
    "\n",
    "Steps:\n",
    "\n",
    "i. 計算 Z-score:  \n",
    "\n",
    "    stats.zscore()\n",
    "\n",
    "ii. Points above and/or below 1.5 times the IQR should be suspected as possible outliers.\n",
    "\n",
    "\n",
    "Example: 使用 stats.zscore 去除異常值(outlier)\n",
    "    \n",
    "    # Print: before dropping\n",
    "    print(numeric_cols.mean())\n",
    "    print(numeric_cols.median())\n",
    "    print(numeric_cols.max())\n",
    "\n",
    "    # Create index of rows to keep\n",
    "    idx = (np.abs(stats.zscore(numeric_cols)) < 3).all(axis=1)\n",
    "  \n",
    "    # Concatenate numeric and categoric subsets\n",
    "    ld_out_drop = pd.concat([numeric_cols.loc[idx], categoric_cols.loc[idx]], axis=1)\n",
    "\n",
    "    # Print: after dropping\n",
    "    print(ld_out_drop.mean())\n",
    "    print(ld_out_drop.median())\n",
    "    print(ld_out_drop.max())\n",
    "\n",
    "(2) Winsorizing 方法處理異常值(outliers)\n",
    "\n",
    "    mstats.winsorize(limits=[0.05, 0.05])\n",
    "\n",
    "Example: 使用 mstats.winsorize 去除異常值(outlier)\n",
    "\n",
    "    # Print: before winsorize\n",
    "    print(df['A'].mean())\n",
    "    print(df['A'].median())\n",
    "    print(df['A'].max())\n",
    "\n",
    "    # Winsorize numeric columns\n",
    "    df_win = mstats.winsorize(df['A'], limits=[0.05, 0.05])\n",
    "\n",
    "    # Convert to DataFrame, reassign column name\n",
    "    df_out = pd.DataFrame(df_win, columns=['A'])\n",
    "\n",
    "    # Print: after winsorize\n",
    "    print(df_out.mean())\n",
    "    print(df_out.median())\n",
    "    print(df_out.max())\n",
    "\n",
    "(3) 以統計量處理異常值\n",
    "\n",
    "    np.where(condition, true, false)\n",
    "\n",
    "Example: 使用 np.where() 將異常值(outlier)用中位數(median) 取代\n",
    "    \n",
    "    # Print: before replace with median\n",
    "    print(df['A'].mean())\n",
    "    print(df['A'].median())\n",
    "    print(df['A'].max())\n",
    "\n",
    "    # Find median\n",
    "    median = df.loc[df['A'] < threshold, 'A'].median()\n",
    "    df['A'] = np.where(df['A'] > threshold, median, df['A'])\n",
    "\n",
    "    # Print: after replace with median\n",
    "    print(df['A'].mean())\n",
    "    print(df['A'].median())\n",
    "    print(df['A'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 資料縮放(Scaling)\n",
    "\n",
    "#### 1. 資料特徵縮放(feature scaling)\n",
    "\n",
    "- Dataset features are continuous and on different scales\n",
    "\n",
    "\n",
    "- Dataset features have high variance\n",
    "\n",
    "\n",
    "- Model with linear characteristics / in linear space\n",
    "\n",
    "\n",
    "- Transforms to approximately normal distribution\n",
    "\n",
    "\n",
    "#### 2. 標準化(Standardization): Z-score standardization\n",
    "\n",
    "(1) Scales to mean = 0 and sd = 1\n",
    "\n",
    "(2) Scaling functions: \n",
    "\n",
    "    scikit-learn.preprocessing.StandardScaler()\n",
    "\n",
    "Example: 使用 Z-score 標準化資料\n",
    "\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    \n",
    "    # Subset features\n",
    "    numeric_cols = df.select_dtypes(include=[np.number])\n",
    "    categoric_cols = df.select_dtypes(include=[object])\n",
    "\n",
    "    # Instantiate\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Fit and transform, convert to DF\n",
    "    numeric_cols_scaled = scaler.fit_transform(numeric_cols)\n",
    "    numeric_cols_scaledDF = pd.DataFrame(numeric_cols_scaled, columns=numeric_cols.columns)\n",
    "\n",
    "    # Concatenate categoric columns to scaled numeric columns\n",
    "    final_DF = pd.concat([categoric_cols, numeric_cols_scaledDF], axis=1)\n",
    "    print(final_DF.head())\n",
    "    print(final_DF.var())\n",
    "\n",
    "#### 3. 歸一化(Normalization): Min/max normalizing\n",
    "\n",
    "(1) Scales to between (0, 1)\n",
    "\n",
    "(2) Scaling functions: \n",
    "\n",
    "    sklearn.preprocessing.MinMaxScaler()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
