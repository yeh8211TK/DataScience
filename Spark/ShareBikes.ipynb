{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "global Path\n",
    "if sc.master[0:5]==\"local\":\n",
    "    Path=\"file:///home/vmauser/pythonwork/PythonProject/\"\n",
    "else:\n",
    "    Path=\"file:/home/vmauser/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17379\n",
      "17\n",
      "['instant', 'dteday', 'season', 'yr', 'mnth', 'hr', 'holiday', 'weekday', 'workingday', 'weathersit', 'temp', 'atemp', 'hum', 'windspeed', 'casual', 'registered', 'cnt']\n"
     ]
    }
   ],
   "source": [
    "hour_df=sqlContext.read.format(\"csv\").option(\"header\", \"true\").load(Path+\"data/hour.csv\")\n",
    "\n",
    "print(hour_df.count())\n",
    "print(len(hour_df.columns))\n",
    "print(hour_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping redundant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- season: string (nullable = true)\n",
      " |-- mnth: string (nullable = true)\n",
      " |-- hr: string (nullable = true)\n",
      " |-- holiday: string (nullable = true)\n",
      " |-- weekday: string (nullable = true)\n",
      " |-- workingday: string (nullable = true)\n",
      " |-- weathersit: string (nullable = true)\n",
      " |-- temp: string (nullable = true)\n",
      " |-- atemp: string (nullable = true)\n",
      " |-- hum: string (nullable = true)\n",
      " |-- windspeed: string (nullable = true)\n",
      " |-- cnt: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hour_df=hour_df.drop(\"instant\").drop(\"dteday\").drop(\"yr\").drop(\"casual\").drop(\"registered\")\n",
    "hour_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Type transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- season: double (nullable = true)\n",
      " |-- mnth: double (nullable = true)\n",
      " |-- hr: double (nullable = true)\n",
      " |-- holiday: double (nullable = true)\n",
      " |-- weekday: double (nullable = true)\n",
      " |-- workingday: double (nullable = true)\n",
      " |-- weathersit: double (nullable = true)\n",
      " |-- temp: double (nullable = true)\n",
      " |-- atemp: double (nullable = true)\n",
      " |-- hum: double (nullable = true)\n",
      " |-- windspeed: double (nullable = true)\n",
      " |-- cnt: double (nullable = true)\n",
      "\n",
      "None\n",
      "+------+----+---+-------+-------+----------+----------+----+------+----+---------+----+\n",
      "|season|mnth| hr|holiday|weekday|workingday|weathersit|temp| atemp| hum|windspeed| cnt|\n",
      "+------+----+---+-------+-------+----------+----------+----+------+----+---------+----+\n",
      "|   1.0| 1.0|0.0|    0.0|    6.0|       0.0|       1.0|0.24|0.2879|0.81|      0.0|16.0|\n",
      "|   1.0| 1.0|1.0|    0.0|    6.0|       0.0|       1.0|0.22|0.2727| 0.8|      0.0|40.0|\n",
      "|   1.0| 1.0|2.0|    0.0|    6.0|       0.0|       1.0|0.22|0.2727| 0.8|      0.0|32.0|\n",
      "|   1.0| 1.0|3.0|    0.0|    6.0|       0.0|       1.0|0.24|0.2879|0.75|      0.0|13.0|\n",
      "|   1.0| 1.0|4.0|    0.0|    6.0|       0.0|       1.0|0.24|0.2879|0.75|      0.0| 1.0|\n",
      "+------+----+---+-------+-------+----------+----------+----+------+----+---------+----+\n",
      "only showing top 5 rows\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "hour_df=hour_df.select([col(column).cast(\"double\").alias(column) for column in hour_df.columns])\n",
    "\n",
    "print hour_df.printSchema()\n",
    "print(hour_df.show(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train/test splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[season: double, mnth: double, hr: double, holiday: double, weekday: double, workingday: double, weathersit: double, temp: double, atemp: double, hum: double, windspeed: double, cnt: double]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df, test_df=hour_df.randomSplit([0.7, 0.3])\n",
    "train_df.cache()\n",
    "test_df.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision tree regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['season', 'mnth', 'hr', 'holiday', 'weekday', 'workingday', 'weathersit', 'temp', 'atemp', 'hum', 'windspeed']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[VectorAssembler_c190bbc9563c,\n",
       " VectorIndexer_fcad48added4,\n",
       " DecisionTreeRegressor_276d5815a61e]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorIndexer, VectorAssembler\n",
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "\n",
    "# Collect the feature columns\n",
    "featuresCols=hour_df.columns[:-1]\n",
    "print(featuresCols)\n",
    "\n",
    "vectorAssembler=VectorAssembler(inputCols=featuresCols, outputCol=\"Afeatures\")\n",
    "vectorIndexer=VectorIndexer(inputCol=\"Afeatures\", outputCol=\"features\", maxCategories=24)\n",
    "dt=DecisionTreeRegressor(labelCol=\"cnt\", featuresCol=\"features\")\n",
    "\n",
    "dt_pipeline=Pipeline(stages=[vectorAssembler, vectorIndexer, dt])\n",
    "dt_pipeline.getStages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'DecisionTreeRegressionModel (uid=DecisionTreeRegressor_276d5815a61e) of depth 5 with 63 nodes\\n  If (feature 2 in {0.0,1.0,2.0,3.0,4.0,5.0,6.0,22.0,23.0})\\n   If (feature 2 in {0.0,1.0,2.0,3.0,4.0,5.0})\\n    If (feature 2 in {2.0,3.0,4.0,5.0})\\n     If (feature 4 in {1.0,2.0,3.0,4.0,5.0})\\n      If (feature 2 in {2.0,3.0,4.0})\\n       Predict: 6.587392550143266\\n      Else (feature 2 not in {2.0,3.0,4.0})\\n       Predict: 24.722666666666665\\n     Else (feature 4 not in {1.0,2.0,3.0,4.0,5.0})\\n      If (fe'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipelineModel=dt_pipeline.fit(train_df)\n",
    "pipelineModel.stages[2].toDebugString[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['season', 'mnth', 'hr', 'holiday', 'weekday', 'workingday', 'weathersit', 'temp', 'atemp', 'hum', 'windspeed', 'cnt', 'Afeatures', 'features', 'prediction']\n"
     ]
    }
   ],
   "source": [
    "predicted_df=pipelineModel.transform(test_df)\n",
    "print(predicted_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+---+-------+-------+----------+----------+----+------+----+---------+----+-----------------+\n",
      "|season|mnth| hr|holiday|weekday|workingday|weathersit|temp| atemp| hum|windspeed| cnt|       prediction|\n",
      "+------+----+---+-------+-------+----------+----------+----+------+----+---------+----+-----------------+\n",
      "|   1.0| 1.0|0.0|    0.0|    0.0|       0.0|       1.0|0.16|0.1364| 0.8|   0.2985|52.0|54.21582733812949|\n",
      "|   1.0| 1.0|0.0|    0.0|    0.0|       0.0|       1.0|0.36|0.3788|0.66|      0.0|48.0|54.21582733812949|\n",
      "|   1.0| 1.0|0.0|    0.0|    2.0|       1.0|       1.0|0.14|0.1667|0.59|   0.1045|12.0|37.56857142857143|\n",
      "|   1.0| 1.0|0.0|    0.0|    2.0|       1.0|       2.0|0.26|0.2273| 0.7|   0.3284|12.0|37.56857142857143|\n",
      "|   1.0| 1.0|0.0|    0.0|    3.0|       1.0|       1.0| 0.2|0.2576|0.64|      0.0| 6.0|37.56857142857143|\n",
      "|   1.0| 1.0|0.0|    0.0|    3.0|       1.0|       1.0|0.26| 0.303|0.81|      0.0|28.0|37.56857142857143|\n",
      "|   1.0| 1.0|0.0|    0.0|    4.0|       1.0|       1.0|0.18|0.2424|0.55|      0.0|11.0|37.56857142857143|\n",
      "|   1.0| 1.0|0.0|    0.0|    6.0|       0.0|       1.0|0.36|0.3485| 0.5|   0.1642|79.0|54.21582733812949|\n",
      "|   1.0| 1.0|0.0|    1.0|    1.0|       0.0|       1.0| 0.4|0.4091| 0.4|   0.4627|39.0|37.56857142857143|\n",
      "|   1.0| 1.0|1.0|    0.0|    0.0|       0.0|       1.0|0.26|0.2727|0.56|   0.1343|23.0|54.21582733812949|\n",
      "+------+----+---+-------+-------+----------+----------+----+------+----+---------+----+-----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted_df.select('season', 'mnth', 'hr', 'holiday', 'weekday', 'workingday',\\\n",
    "'weathersit', 'temp', 'atemp', 'hum', 'windspeed', 'cnt', 'prediction').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97.34398927140036"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "evaluator=RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"cnt\", metricName=\"rmse\")\n",
    "\n",
    "rmse=evaluator.evaluate(predicted_df)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision tree regression with TrainValidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'DecisionTreeRegressionModel (uid=DecisionTreeRegressor_276d5815a61e) of depth 10 with 1833 nodes\\n  If (feature 2 in {0.0,1.0,2.0,3.0,4.0,5.0,6.0,22.0,23.0})\\n   If (feature 2 in {0.0,1.0,2.0,3.0,4.0,5.0})\\n    If (feature 2 in {2.0,3.0,4.0,5.0})\\n     If (feature 4 in {1.0,2.0,3.0,4.0,5.0})\\n      If (feature 2 in {2.0,3.0,4.0})\\n       If (feature 2 in {3.0,4.0})\\n        If (feature 1 in {0.0,1.0,2.0,3.0,11.0})\\n         If (feature 0 in {0.0})\\n          If (feature 7 <= 0.33)\\n           If (feature '"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorIndexer, VectorAssembler\n",
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "featuresCols=hour_df.columns[:-1]\n",
    "\n",
    "vectorAssembler=VectorAssembler(inputCols=featuresCols, outputCol=\"Afeatures\")\n",
    "\n",
    "vectorIndexer=VectorIndexer(inputCol=\"Afeatures\", outputCol=\"features\", maxCategories=24)\n",
    "\n",
    "dt=DecisionTreeRegressor(labelCol=\"cnt\", featuresCol=\"features\")\n",
    "\n",
    "paramGrid=ParamGridBuilder().addGrid(dt.maxDepth, [5, 10, 15, 25])\\\n",
    ".addGrid(dt.maxBins, [25, 35, 45, 50])\\\n",
    ".build()\n",
    "\n",
    "evaluator=RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"cnt\", metricName=\"rmse\")\n",
    "\n",
    "tvs=TrainValidationSplit(estimator=dt, evaluator=evaluator,\\\n",
    "                         estimatorParamMaps=paramGrid, trainRatio=0.8)\n",
    "\n",
    "tvs_pipeline=Pipeline(stages=[vectorAssembler, vectorIndexer, tvs])\n",
    "tvs_pipelineModel=tvs_pipeline.fit(train_df)\n",
    "\n",
    "bestModel=tvs_pipelineModel.stages[2].bestModel\n",
    "bestModel.toDebugString[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97.34398927140036"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions=tvs_pipelineModel.transform(test_df)\n",
    "rmse=evaluator.evaluate(predictions)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision tree regression with CrossValidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81.3626354870387"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorIndexer, VectorAssembler\n",
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "featuresCols=hour_df.columns[:-1]\n",
    "\n",
    "vectorAssembler=VectorAssembler(inputCols=featuresCols, outputCol=\"Afeatures\")\n",
    "\n",
    "vectorIndexer=VectorIndexer(inputCol=\"Afeatures\", outputCol=\"features\", maxCategories=24)\n",
    "\n",
    "dt=DecisionTreeRegressor(labelCol=\"cnt\", featuresCol=\"features\")\n",
    "\n",
    "paramGrid=ParamGridBuilder().addGrid(dt.maxDepth, [5, 10, 15, 25])\\\n",
    ".addGrid(dt.maxBins, [25, 35, 45, 50])\\\n",
    ".build()\n",
    "\n",
    "evaluator=RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"cnt\", metricName=\"rmse\")\n",
    "#-----------------------------------------------------------------------------------------------------\n",
    "cv=CrossValidator(estimator=dt, evaluator=evaluator, estimatorParamMaps=paramGrid, numFolds=3)\n",
    "\n",
    "cv_pipeline=Pipeline(stages=[vectorAssembler, vectorIndexer, cv])\n",
    "cv_pipelineModel=cv_pipeline.fit(train_df)\n",
    "\n",
    "predictions=tvs_pipelineModel.transform(test_df)\n",
    "rmse=evaluator.evaluate(predictions)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+---+-------+-------+----------+----------+----+------+----+---------+----+------------------+\n",
      "|season|mnth| hr|holiday|weekday|workingday|weathersit|temp| atemp| hum|windspeed| cnt|        prediction|\n",
      "+------+----+---+-------+-------+----------+----------+----+------+----+---------+----+------------------+\n",
      "|   1.0| 1.0|0.0|    0.0|    0.0|       0.0|       1.0|0.16|0.1364| 0.8|   0.2985|52.0|              43.0|\n",
      "|   1.0| 1.0|0.0|    0.0|    0.0|       0.0|       1.0|0.36|0.3788|0.66|      0.0|48.0|              91.0|\n",
      "|   1.0| 1.0|0.0|    0.0|    2.0|       1.0|       1.0|0.14|0.1667|0.59|   0.1045|12.0|13.058823529411764|\n",
      "|   1.0| 1.0|0.0|    0.0|    2.0|       1.0|       2.0|0.26|0.2273| 0.7|   0.3284|12.0|20.558139534883722|\n",
      "|   1.0| 1.0|0.0|    0.0|    3.0|       1.0|       1.0| 0.2|0.2576|0.64|      0.0| 6.0|13.058823529411764|\n",
      "|   1.0| 1.0|0.0|    0.0|    3.0|       1.0|       1.0|0.26| 0.303|0.81|      0.0|28.0|20.558139534883722|\n",
      "|   1.0| 1.0|0.0|    0.0|    4.0|       1.0|       1.0|0.18|0.2424|0.55|      0.0|11.0|13.058823529411764|\n",
      "|   1.0| 1.0|0.0|    0.0|    6.0|       0.0|       1.0|0.36|0.3485| 0.5|   0.1642|79.0|60.333333333333336|\n",
      "|   1.0| 1.0|0.0|    1.0|    1.0|       0.0|       1.0| 0.4|0.4091| 0.4|   0.4627|39.0|36.411764705882355|\n",
      "|   1.0| 1.0|1.0|    0.0|    0.0|       0.0|       1.0|0.26|0.2727|0.56|   0.1343|23.0|45.111111111111114|\n",
      "+------+----+---+-------+-------+----------+----------+----+------+----+---------+----+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.select('season', 'mnth', 'hr', 'holiday', 'weekday', 'workingday',\\\n",
    "'weathersit', 'temp', 'atemp', 'hum', 'windspeed', 'cnt', 'prediction').show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient boost tree regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77.72245187508419"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorIndexer, VectorAssembler\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "featuresCols=hour_df.columns[:-1]\n",
    "\n",
    "vectorAssembler=VectorAssembler(inputCols=featuresCols, outputCol=\"Afeatures\")\n",
    "vectorIndexer=VectorIndexer(inputCol=\"Afeatures\", outputCol=\"features\", maxCategories=24)\n",
    "gbt=GBTRegressor(labelCol=\"cnt\", featuresCol=\"features\")\n",
    "\n",
    "gbt_pipeline=Pipeline(stages=[vectorAssembler, vectorIndexer, gbt])\n",
    "\n",
    "gbt_pipelineModel=gbt_pipeline.fit(train_df)\n",
    "predictions=gbt_pipelineModel.transform(test_df)\n",
    "\n",
    "evaluator=RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"cnt\", metricName=\"rmse\")\n",
    "\n",
    "rmse=evaluator.evaluate(predictions)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient boost tree regression with CrossValidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+---+-------+-------+----------+----------+----+------+----+---------+----+------------------+\n",
      "|season|mnth| hr|holiday|weekday|workingday|weathersit|temp| atemp| hum|windspeed| cnt|        prediction|\n",
      "+------+----+---+-------+-------+----------+----------+----+------+----+---------+----+------------------+\n",
      "|   1.0| 1.0|0.0|    0.0|    0.0|       0.0|       1.0|0.16|0.1364| 0.8|   0.2985|52.0|30.020968047810054|\n",
      "|   1.0| 1.0|0.0|    0.0|    0.0|       0.0|       1.0|0.36|0.3788|0.66|      0.0|48.0|107.53821688440438|\n",
      "|   1.0| 1.0|0.0|    0.0|    2.0|       1.0|       1.0|0.14|0.1667|0.59|   0.1045|12.0|20.243304002033565|\n",
      "|   1.0| 1.0|0.0|    0.0|    2.0|       1.0|       2.0|0.26|0.2273| 0.7|   0.3284|12.0|25.402519433813612|\n",
      "|   1.0| 1.0|0.0|    0.0|    3.0|       1.0|       1.0| 0.2|0.2576|0.64|      0.0| 6.0| 22.17624724769169|\n",
      "|   1.0| 1.0|0.0|    0.0|    3.0|       1.0|       1.0|0.26| 0.303|0.81|      0.0|28.0|30.432900917798495|\n",
      "|   1.0| 1.0|0.0|    0.0|    4.0|       1.0|       1.0|0.18|0.2424|0.55|      0.0|11.0| 20.08349916595001|\n",
      "|   1.0| 1.0|0.0|    0.0|    6.0|       0.0|       1.0|0.36|0.3485| 0.5|   0.1642|79.0|61.664253779888185|\n",
      "|   1.0| 1.0|0.0|    1.0|    1.0|       0.0|       1.0| 0.4|0.4091| 0.4|   0.4627|39.0| 52.63604384188662|\n",
      "|   1.0| 1.0|1.0|    0.0|    0.0|       0.0|       1.0|0.26|0.2727|0.56|   0.1343|23.0| 36.01842047342577|\n",
      "+------+----+---+-------+-------+----------+----------+----+------+----+---------+----+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorIndexer, VectorAssembler\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "featuresCols=hour_df.columns[:-1]\n",
    "\n",
    "vectorAssembler=VectorAssembler(inputCols=featuresCols, outputCol=\"Afeatures\")\n",
    "vectorIndexer=VectorIndexer(inputCol=\"Afeatures\", outputCol=\"features\", maxCategories=24)\n",
    "gbt=GBTRegressor(labelCol=\"cnt\", featuresCol=\"features\")\n",
    "\n",
    "paramGrid=ParamGridBuilder().addGrid(gbt.maxDepth, [5, 10])\\\n",
    ".addGrid(gbt.maxBins, [25, 40])\\\n",
    ".addGrid(gbt.maxIter, [10, 50])\\\n",
    ".build()\n",
    "\n",
    "evaluator=RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"cnt\", metricName=\"rmse\")\n",
    "\n",
    "cv=CrossValidator(estimator=gbt, evaluator=evaluator, estimatorParamMaps=paramGrid, numFolds=3)\n",
    "\n",
    "cv_pipeline=Pipeline(stages=[vectorAssembler, vectorIndexer, cv])\n",
    "\n",
    "cv_pipelineModel=cv_pipeline.fit(train_df)\n",
    "\n",
    "predictions=cv_pipelineModel.transform(test_df)\n",
    "\n",
    "predictions.select('season', 'mnth', 'hr', 'holiday', 'weekday', 'workingday',\\\n",
    "'weathersit', 'temp', 'atemp', 'hum', 'windspeed', 'cnt', 'prediction').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71.9596662703907"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse=evaluator.evaluate(predictions)\n",
    "rmse"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
