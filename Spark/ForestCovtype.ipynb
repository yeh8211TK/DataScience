{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "global Path\n",
    "if sc.master[0:5]==\"local\":\n",
    "    Path=\"file:///home/vmauser/pythonwork/PythonProject/\"\n",
    "else:\n",
    "    Path=\"file:/home/vmauser/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "581011\n",
      "55\n",
      "['2596', '51', '3', '258', '04', '510', '221', '232', '148', '6279', '110', '011', '012', '013', '014', '015', '016', '017', '018', '019', '020', '021', '022', '023', '024', '025', '026', '027', '028', '029', '030', '031', '032', '033', '034', '035', '036', '037', '038', '039', '040', '041', '142', '043', '044', '045', '046', '047', '048', '049', '050', '051', '052', '053', '5']\n",
      "root\n",
      " |-- 2596: string (nullable = true)\n",
      " |-- 51: string (nullable = true)\n",
      " |-- 3: string (nullable = true)\n",
      " |-- 258: string (nullable = true)\n",
      " |-- 04: string (nullable = true)\n",
      " |-- 510: string (nullable = true)\n",
      " |-- 221: string (nullable = true)\n",
      " |-- 232: string (nullable = true)\n",
      " |-- 148: string (nullable = true)\n",
      " |-- 6279: string (nullable = true)\n",
      " |-- 110: string (nullable = true)\n",
      " |-- 011: string (nullable = true)\n",
      " |-- 012: string (nullable = true)\n",
      " |-- 013: string (nullable = true)\n",
      " |-- 014: string (nullable = true)\n",
      " |-- 015: string (nullable = true)\n",
      " |-- 016: string (nullable = true)\n",
      " |-- 017: string (nullable = true)\n",
      " |-- 018: string (nullable = true)\n",
      " |-- 019: string (nullable = true)\n",
      " |-- 020: string (nullable = true)\n",
      " |-- 021: string (nullable = true)\n",
      " |-- 022: string (nullable = true)\n",
      " |-- 023: string (nullable = true)\n",
      " |-- 024: string (nullable = true)\n",
      " |-- 025: string (nullable = true)\n",
      " |-- 026: string (nullable = true)\n",
      " |-- 027: string (nullable = true)\n",
      " |-- 028: string (nullable = true)\n",
      " |-- 029: string (nullable = true)\n",
      " |-- 030: string (nullable = true)\n",
      " |-- 031: string (nullable = true)\n",
      " |-- 032: string (nullable = true)\n",
      " |-- 033: string (nullable = true)\n",
      " |-- 034: string (nullable = true)\n",
      " |-- 035: string (nullable = true)\n",
      " |-- 036: string (nullable = true)\n",
      " |-- 037: string (nullable = true)\n",
      " |-- 038: string (nullable = true)\n",
      " |-- 039: string (nullable = true)\n",
      " |-- 040: string (nullable = true)\n",
      " |-- 041: string (nullable = true)\n",
      " |-- 142: string (nullable = true)\n",
      " |-- 043: string (nullable = true)\n",
      " |-- 044: string (nullable = true)\n",
      " |-- 045: string (nullable = true)\n",
      " |-- 046: string (nullable = true)\n",
      " |-- 047: string (nullable = true)\n",
      " |-- 048: string (nullable = true)\n",
      " |-- 049: string (nullable = true)\n",
      " |-- 050: string (nullable = true)\n",
      " |-- 051: string (nullable = true)\n",
      " |-- 052: string (nullable = true)\n",
      " |-- 053: string (nullable = true)\n",
      " |-- 5: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "covtype_df=sqlContext.read.format(\"csv\").option(\"header\", \"true\").option(\n",
    "    \"delimiter\", \",\").load(Path+\"data/covtype.data\")\n",
    "\n",
    "print(covtype_df.count())\n",
    "print(len(covtype_df.columns))\n",
    "print(covtype_df.columns)\n",
    "covtype_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Type transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- 2596: double (nullable = true)\n",
      " |-- 51: double (nullable = true)\n",
      " |-- 3: double (nullable = true)\n",
      " |-- 258: double (nullable = true)\n",
      " |-- 04: double (nullable = true)\n",
      " |-- 510: double (nullable = true)\n",
      " |-- 221: double (nullable = true)\n",
      " |-- 232: double (nullable = true)\n",
      " |-- 148: double (nullable = true)\n",
      " |-- 6279: double (nullable = true)\n",
      " |-- 110: double (nullable = true)\n",
      " |-- 011: double (nullable = true)\n",
      " |-- 012: double (nullable = true)\n",
      " |-- 013: double (nullable = true)\n",
      " |-- 014: double (nullable = true)\n",
      " |-- 015: double (nullable = true)\n",
      " |-- 016: double (nullable = true)\n",
      " |-- 017: double (nullable = true)\n",
      " |-- 018: double (nullable = true)\n",
      " |-- 019: double (nullable = true)\n",
      " |-- 020: double (nullable = true)\n",
      " |-- 021: double (nullable = true)\n",
      " |-- 022: double (nullable = true)\n",
      " |-- 023: double (nullable = true)\n",
      " |-- 024: double (nullable = true)\n",
      " |-- 025: double (nullable = true)\n",
      " |-- 026: double (nullable = true)\n",
      " |-- 027: double (nullable = true)\n",
      " |-- 028: double (nullable = true)\n",
      " |-- 029: double (nullable = true)\n",
      " |-- 030: double (nullable = true)\n",
      " |-- 031: double (nullable = true)\n",
      " |-- 032: double (nullable = true)\n",
      " |-- 033: double (nullable = true)\n",
      " |-- 034: double (nullable = true)\n",
      " |-- 035: double (nullable = true)\n",
      " |-- 036: double (nullable = true)\n",
      " |-- 037: double (nullable = true)\n",
      " |-- 038: double (nullable = true)\n",
      " |-- 039: double (nullable = true)\n",
      " |-- 040: double (nullable = true)\n",
      " |-- 041: double (nullable = true)\n",
      " |-- 142: double (nullable = true)\n",
      " |-- 043: double (nullable = true)\n",
      " |-- 044: double (nullable = true)\n",
      " |-- 045: double (nullable = true)\n",
      " |-- 046: double (nullable = true)\n",
      " |-- 047: double (nullable = true)\n",
      " |-- 048: double (nullable = true)\n",
      " |-- 049: double (nullable = true)\n",
      " |-- 050: double (nullable = true)\n",
      " |-- 051: double (nullable = true)\n",
      " |-- 052: double (nullable = true)\n",
      " |-- 053: double (nullable = true)\n",
      " |-- 5: double (nullable = true)\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "covtype_df=covtype_df.select([col(column).cast(\"double\").alias(column) \n",
    "                             for column in covtype_df.columns])\n",
    "\n",
    "print covtype_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2596', '51', '3', '258', '04', '510', '221', '232', '148', '6279', '110', '011', '012', '013', '014', '015', '016', '017', '018', '019', '020', '021', '022', '023', '024', '025', '026', '027', '028', '029', '030', '031', '032', '033', '034', '035', '036', '037', '038', '039', '040', '041', '142', '043', '044', '045', '046', '047', '048', '049', '050', '051', '052', '053']\n"
     ]
    }
   ],
   "source": [
    "featuresCols=covtype_df.columns[:54]\n",
    "print(featuresCols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+---+-----+----+-----+-----+-----+-----+------+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+-----+\n",
      "|  2596|  51|  3|  258|  04|  510|  221|  232|  148|  6279|110|011|012|013|014|015|016|017|018|019|020|021|022|023|024|025|026|027|028|029|030|031|032|033|034|035|036|037|038|039|040|041|142|043|044|045|046|047|048|049|050|051|052|053|label|\n",
      "+------+----+---+-----+----+-----+-----+-----+-----+------+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+-----+\n",
      "|2590.0|56.0|2.0|212.0|-6.0|390.0|220.0|235.0|151.0|6225.0|1.0|0.0|0.0|0.0|0.0|0.0|0.0|0.0|0.0|0.0|0.0|0.0|0.0|0.0|0.0|0.0|0.0|0.0|0.0|0.0|0.0|0.0|0.0|0.0|0.0|0.0|0.0|0.0|0.0|0.0|0.0|0.0|1.0|0.0|0.0|0.0|0.0|0.0|0.0|0.0|0.0|0.0|0.0|0.0|  4.0|\n",
      "+------+----+---+-----+----+-----+-----+-----+-----+------+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+-----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "covtype_df=covtype_df.withColumn(\"label\", covtype_df[\"5\"]-1).drop(\"5\")\n",
    "covtype_df.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train/test splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[2596: double, 51: double, 3: double, 258: double, 04: double, 510: double, 221: double, 232: double, 148: double, 6279: double, 110: double, 011: double, 012: double, 013: double, 014: double, 015: double, 016: double, 017: double, 018: double, 019: double, 020: double, 021: double, 022: double, 023: double, 024: double, 025: double, 026: double, 027: double, 028: double, 029: double, 030: double, 031: double, 032: double, 033: double, 034: double, 035: double, 036: double, 037: double, 038: double, 039: double, 040: double, 041: double, 142: double, 043: double, 044: double, 045: double, 046: double, 047: double, 048: double, 049: double, 050: double, 051: double, 052: double, 053: double, label: double]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df, test_df=covtype_df.randomSplit([0.7, 0.3])\n",
    "train_df.cache()\n",
    "test_df.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[VectorAssembler_536f6567f14f, DecisionTreeClassifier_38375228d5ca]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "\n",
    "vectorAssembler=VectorAssembler(inputCols=featuresCols, outputCol=\"features\")\n",
    "\n",
    "dt=DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features\",\n",
    "                          impurity=\"gini\", maxDepth=5, maxBins=20)\n",
    "\n",
    "dt_pipeline=Pipeline(stages=[vectorAssembler, dt])\n",
    "dt_pipeline.getStages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'DecisionTreeClassificationModel (uid=DecisionTreeClassifier_38375228d5ca) of depth 5 with 39 nodes\\n  If (feature 0 <= 3053.5)\\n   If (feature 0 <= 2567.5)\\n    If (feature 10 <= 0.5)\\n     If (feature 0 <= 2398.5)\\n      If (feature 3 <= 15.0)\\n       Predict: 3.0\\n      Else (feature 3 > 15.0)\\n       Predict: 2.0\\n     Else (feature 0 > 2398.5)\\n      Predict: 2.0\\n    Else (feature 10 > 0.5)\\n     Predict: 1.0\\n   Else (feature 0 > 2567.5)\\n    If (feature 0 <= 2964.5)\\n     If (feature 15 <= 0.5)\\n      Pr'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipelineModel=dt_pipeline.fit(train_df)\n",
    "pipelineModel.stages[1].toDebugString[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2596', '51', '3', '258', '04', '510', '221', '232', '148', '6279', '110', '011', '012', '013', '014', '015', '016', '017', '018', '019', '020', '021', '022', '023', '024', '025', '026', '027', '028', '029', '030', '031', '032', '033', '034', '035', '036', '037', '038', '039', '040', '041', '142', '043', '044', '045', '046', '047', '048', '049', '050', '051', '052', '053', 'label', 'features', 'rawPrediction', 'probability', 'prediction']\n"
     ]
    }
   ],
   "source": [
    "predicted=pipelineModel.transform(test_df)\n",
    "print(predicted.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+-----+----------+\n",
      "|            features|       rawPrediction|         probability|label|prediction|\n",
      "+--------------------+--------------------+--------------------+-----+----------+\n",
      "|(54,[0,1,2,3,4,5,...|[0.0,441.0,11859....|[0.0,0.0241842610...|  2.0|       2.0|\n",
      "|(54,[0,1,2,3,4,5,...|[0.0,441.0,11859....|[0.0,0.0241842610...|  5.0|       2.0|\n",
      "|(54,[0,1,2,3,4,5,...|[0.0,441.0,11859....|[0.0,0.0241842610...|  5.0|       2.0|\n",
      "|(54,[0,1,2,3,4,5,...|[0.0,441.0,11859....|[0.0,0.0241842610...|  5.0|       2.0|\n",
      "|(54,[0,1,2,3,4,5,...|[0.0,441.0,11859....|[0.0,0.0241842610...|  2.0|       2.0|\n",
      "|(54,[0,1,2,3,4,5,...|[0.0,441.0,11859....|[0.0,0.0241842610...|  5.0|       2.0|\n",
      "|(54,[0,1,2,3,4,5,...|[0.0,441.0,11859....|[0.0,0.0241842610...|  5.0|       2.0|\n",
      "|(54,[0,1,2,3,4,5,...|[0.0,441.0,11859....|[0.0,0.0241842610...|  5.0|       2.0|\n",
      "|(54,[0,1,2,3,4,5,...|[0.0,441.0,11859....|[0.0,0.0241842610...|  5.0|       2.0|\n",
      "|(54,[0,1,2,3,4,5,...|[0.0,441.0,11859....|[0.0,0.0241842610...|  5.0|       2.0|\n",
      "+--------------------+--------------------+--------------------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(probability=DenseVector([0.0, 0.0242, 0.6503, 0.0607, 0.0, 0.2648, 0.0]), prediction=2.0),\n",
       " Row(probability=DenseVector([0.0, 0.0242, 0.6503, 0.0607, 0.0, 0.2648, 0.0]), prediction=2.0),\n",
       " Row(probability=DenseVector([0.0, 0.0242, 0.6503, 0.0607, 0.0, 0.2648, 0.0]), prediction=2.0),\n",
       " Row(probability=DenseVector([0.0, 0.0242, 0.6503, 0.0607, 0.0, 0.2648, 0.0]), prediction=2.0),\n",
       " Row(probability=DenseVector([0.0, 0.0242, 0.6503, 0.0607, 0.0, 0.2648, 0.0]), prediction=2.0),\n",
       " Row(probability=DenseVector([0.0, 0.0242, 0.6503, 0.0607, 0.0, 0.2648, 0.0]), prediction=2.0),\n",
       " Row(probability=DenseVector([0.0, 0.0242, 0.6503, 0.0607, 0.0, 0.2648, 0.0]), prediction=2.0),\n",
       " Row(probability=DenseVector([0.0, 0.0242, 0.6503, 0.0607, 0.0, 0.2648, 0.0]), prediction=2.0),\n",
       " Row(probability=DenseVector([0.0, 0.0242, 0.6503, 0.0607, 0.0, 0.2648, 0.0]), prediction=2.0),\n",
       " Row(probability=DenseVector([0.0, 0.0242, 0.6503, 0.0607, 0.0, 0.2648, 0.0]), prediction=2.0)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted.select(\"features\", \"rawPrediction\", \"probability\", \"label\", \"prediction\").show(10)\n",
    "predicted.select(\"probability\", \"prediction\").take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7014970711968546"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator=MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"label\", \n",
    "                                            metricName=\"accuracy\")\n",
    "\n",
    "accuracy=evaluator.evaluate(predicted)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision tree with TrainValidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'DecisionTreeClassificationModel (uid=DecisionTreeClassifier_2d0b05f495a2) of depth 20 with 32483 nodes\\n  If (feature 0 <= 2697.5)\\n   If (feature 0 <= 2471.5)\\n    If (feature 23 <= 0.5)\\n     If (feature 3 <= 15.0)\\n      If (feature 12 <= 0.5)\\n       If (feature 5 <= 712.0)\\n        If (feature 9 <= 980.0)\\n         If (feature 6 <= 211.5)\\n          If (feature 14 <= 0.5)\\n           If (feature 5 <= 298.5)\\n            If (feature 18 <= 0.5)\\n             If (feature 8 <= 157.5)\\n              If (feat'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "vectorAssembler=VectorAssembler(inputCols=featuresCols, outputCol=\"features\")\n",
    "\n",
    "dt=DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features\",\n",
    "                          impurity=\"gini\", maxDepth=5, maxBins=20)\n",
    "\n",
    "paramGrid=ParamGridBuilder().addGrid(dt.impurity, [\"gini\", \"entropy\"])\\\n",
    ".addGrid(dt.maxDepth, [10, 15, 20])\\\n",
    ".addGrid(dt.maxBins, [30, 40, 50])\\\n",
    ".build()\n",
    "\n",
    "evaluator=MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"label\", \n",
    "                                            metricName=\"accuracy\")\n",
    "\n",
    "tvs=TrainValidationSplit(estimator=dt, evaluator=evaluator,\\\n",
    "                         estimatorParamMaps=paramGrid, trainRatio=0.8)\n",
    "\n",
    "tvs_pipeline=Pipeline(stages=[vectorAssembler, tvs])\n",
    "tvs_pipelineModel=tvs_pipeline.fit(train_df)\n",
    "\n",
    "bestModel=tvs_pipelineModel.stages[1].bestModel\n",
    "bestModel.toDebugString[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+----+--------+--------+-----+-----+----------+\n",
      "|  海拔|方位|斜率|垂直距離|水平距離| 陰影|label|prediction|\n",
      "+------+----+----+--------+--------+-----+-----+----------+\n",
      "|1863.0|37.0|17.0|   120.0|    18.0| 90.0|  5.0|       5.0|\n",
      "|1867.0|20.0|15.0|   108.0|    19.0|120.0|  2.0|       2.0|\n",
      "|1871.0|22.0|22.0|    60.0|    12.0| 85.0|  5.0|       5.0|\n",
      "|1872.0|27.0|16.0|    95.0|    22.0|124.0|  2.0|       2.0|\n",
      "|1873.0|30.0|19.0|    67.0|    21.0| 85.0|  2.0|       2.0|\n",
      "|1879.0|28.0|19.0|    30.0|    12.0| 95.0|  5.0|       5.0|\n",
      "|1880.0|13.0|23.0|    90.0|    29.0| 67.0|  5.0|       5.0|\n",
      "|1880.0|35.0|21.0|   150.0|    32.0|150.0|  2.0|       2.0|\n",
      "|1880.0|38.0|21.0|   150.0|    38.0|120.0|  5.0|       5.0|\n",
      "|1883.0|27.0|24.0|   120.0|    24.0|108.0|  5.0|       5.0|\n",
      "+------+----+----+--------+--------+-----+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions=tvs_pipelineModel.transform(test_df)\n",
    "result=predictions.withColumnRenamed(\"2596\", \"海拔\")\\\n",
    ".withColumnRenamed(\"51\", \"方位\")\\\n",
    ".withColumnRenamed(\"3\", \"斜率\")\\\n",
    ".withColumnRenamed(\"258\", \"垂直距離\")\\\n",
    ".withColumnRenamed(\"04\", \"水平距離\")\\\n",
    ".withColumnRenamed(\"510\", \"陰影\")\n",
    "\n",
    "result.select(\"海拔\", \"方位\", \"斜率\", \"垂直距離\", \"水平距離\", \"陰影\", \"label\", \"prediction\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9077771275802324"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy=evaluator.evaluate(predictions)\n",
    "accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
