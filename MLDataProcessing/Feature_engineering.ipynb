{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特徵工程(Feature Engineering)\n",
    "\n",
    "#### 1. 什麼是特徵工程?\n",
    "\n",
    "- 利用已存在的特徵資料創造新的特徵並擷取新的額外資訊\n",
    "\n",
    "\n",
    "- 可以了解特徵之間關係\n",
    "\n",
    "\n",
    "- 處理的方法依據資料集而定(dataset-dependent)\n",
    "\n",
    "\n",
    "- 為一種有效改進預測模型(predictive model)的方法\n",
    "\n",
    "\n",
    "#### 2. 使用特徵工程的優點\n",
    "\n",
    "- 增進學習演算法(learning algorithm)的預測能力\n",
    "\n",
    "\n",
    "- 使機械學習模型有較佳的表現\n",
    "\n",
    "\n",
    "#### 3. 特徵工程的資料種類\n",
    "\n",
    "- 種類資料\n",
    "\n",
    "\n",
    "- 數值資料 (例: 統計量、時間戳)\n",
    "\n",
    "\n",
    "- 文字資料\n",
    "\n",
    "\n",
    "(1) 特徵工程的資料型態表示:\n",
    "\n",
    "a. 指標變數(Indicator variables)\n",
    "\n",
    "- Threshold indicator\n",
    "\n",
    "\n",
    "- Multiple features\n",
    "\n",
    "\n",
    "- Groups of classes\n",
    "\n",
    "\n",
    "b. 交互特徵(Interaction features)\n",
    "\n",
    "- Sum/Difference/Product/Quotient\n",
    "\n",
    "\n",
    "- Other mathematical combos\n",
    "\n",
    "\n",
    "c. 特徵表示(Feature representation)\n",
    "\n",
    "- Datetime stamps\n",
    "\n",
    "\n",
    "- Dummy variables [(n - 1) features for n categories]\n",
    "\n",
    "\n",
    "(2) DataFrame 資料型態\n",
    "\n",
    "a. df.dtypes:\n",
    "\n",
    "- object: string/mixed types\n",
    "\n",
    "\n",
    "- int64: integer\n",
    "\n",
    "\n",
    "- float64: float\n",
    "\n",
    "\n",
    "- datetime64 (or timedelta): datetime\n",
    "\n",
    "\n",
    "b. 欄位型態轉換\n",
    "\n",
    "    df[\"A\"] = df[\"A\"].astype(\"float\")\n",
    "    print(df.dtypes)\n",
    "\n",
    "#### 4. 種類特徵\n",
    "\n",
    "(1) 二元變數(binary variables)\n",
    "\n",
    "a. 使用 Pandas\n",
    "\n",
    "- apply() function:\n",
    "\n",
    "\n",
    "      df[\"Class_enc\"] = df[\"Class\"].apply(lambda val: 1 if val == \"y\" else 0)\n",
    "\n",
    "- replace() function:\n",
    "\n",
    "\n",
    "      df[\"Class_enc\"] = df[\"Class\"].replace({'x': 0, 'y': 1})\n",
    "\n",
    "b. 使用 scikit-learn\n",
    "\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    \n",
    "    le = LabelEncoder()\n",
    "    \n",
    "    df[\"Class_enc\"] = le.fit_transform(df[\"Class\"])\n",
    "\n",
    "(2) 多元變數\n",
    "\n",
    "a. One-hot encoding\n",
    "\n",
    "    pd.get_dummies(df, columns=['Class'], prefix='enc_')\n",
    "\n",
    "b. Dummy encoding\n",
    "\n",
    "    pd.get_dummies(df, columns=['Class'], drop_first=True, prefix='enc_')\n",
    "\n",
    "c. One-hot vs dummies encoding\n",
    "\n",
    "- One-hot encoding: Explainable features that contain the entirely collinear feature due to same information\n",
    "\n",
    "\n",
    "- Dummy encoding: Necessary information without duplication\n",
    "\n",
    "\n",
    "d. 根據種類的數量進行分類 $\\rightarrow$ 用來限制 one-hot/dummy encoding 所產生的大量欄位\n",
    "    \n",
    "    counts = df['Class'].value_counts()\n",
    "    \n",
    "    mask = df['Class'].isin(counts[counts < 5].index)\n",
    "    \n",
    "    df['Class'][mask] = 'Other'\n",
    "\n",
    "**References**: \n",
    "\n",
    "- [Tutorial: (Robust) One Hot Encoding in Python](https://blog.cambridgespark.com/robust-one-hot-encoding-in-python-3e29bfcec77e)\n",
    "\n",
    "\n",
    "- [Handling Categorical Data in Python](https://www.datacamp.com/community/tutorials/categorical-data)\n",
    "\n",
    "#### 5. 數值特徵\n",
    "\n",
    "(1) 統計量: \n",
    "\n",
    "Example: 計算平均\n",
    "\n",
    "    columns = [\"day1\", \"day2\", \"day3\"]\n",
    "    \n",
    "    df[\"mean\"] = df.apply(lambda row: row[columns].mean(), axis=1)\n",
    "\n",
    "(2) 時間格式轉換:\n",
    "\n",
    "    df[\"date_converted\"] = pd.to_datetime(df[\"date\"])\n",
    "    \n",
    "    df[\"month\"] = df[\"date_converted\"].apply(lambda row: row.month)\n",
    "    \n",
    "(3) 二值化數值變數(Binarizing numeric variables):\n",
    "\n",
    "    df['Binary_counts'] = 0\n",
    "    \n",
    "    df.loc[df['Number_of_counts'] > 0, 'Binary_counts'] = 1)\n",
    "    \n",
    "(4) 分箱數值變數(Binning numeric variables):\n",
    "\n",
    "    df['Binned_Group'] = pd.cut(df['Number_of_counts'], bins=[-np.inf, 0, 5, np.inf], labels=[1, 2, 3])\n",
    "\n",
    "#### 6. 文字資料\n",
    "\n",
    "(1) 搜尋與處理流浪字符(stray characters)\n",
    "\n",
    "Example: £ 5000 $\\rightarrow$ 5000.00\n",
    "\n",
    "    # Convert the column to numeric values\n",
    "    coerced_vals = pd.to_numeric(df['dollars'], errors='coerce')\n",
    "\n",
    "    # Find the index of missing values\n",
    "    idx = coerced_vals.isna()\n",
    "\n",
    "    # Print the relevant rows\n",
    "    print(df['dollars'][idx].head())\n",
    "    \n",
    "    df['dollars'] = df['dollars'].str.replace('£', ' ')\n",
    "    df['dollars'] = df['dollars'].astype('float')\n",
    "\n",
    "(2) 文字資料標準化、單詞分割、計數\n",
    "    \n",
    "    # Standardize the text\n",
    "    df['text'] = df['text'].str.lower()\n",
    "    print(df['text'][0])\n",
    "\n",
    "    # Length of text\n",
    "    df['char_cnt'] = df['text'].str.len()\n",
    "    print(df['char_cnt'].head())\n",
    "\n",
    "    # Word splits\n",
    "    df['word_splits'] = df['text'].str.split()\n",
    "    df['word_splits'].head(1)\n",
    "\n",
    "    # Word counts\n",
    "    df['word_cnt'] = df['text'].str.split().str.len()\n",
    "    print(df['word_cnt'].head())\n",
    "\n",
    "    # Average length of word\n",
    "    df['avg_word_len'] = df['char_cnt'] / df['word_cnt']\n",
    "\n",
    "(3) 使用正規表示式(regular expression)處理文字\n",
    "\n",
    "a. 去除非字母的字符\n",
    "\n",
    "    # Removing unwanted characters\n",
    "    df['text'] = df['text'].str.replace('[^a-zA-Z]', ' ')\n",
    "\n",
    "- [a-zA-Z] : All letter characters\n",
    "\n",
    "\n",
    "- [^a-zA-Z] : All non letter characters\n",
    "\n",
    "\n",
    "b. re 模組取出數值\n",
    "\n",
    "    import re\n",
    "    string = \"temperature: 80.0 F\"\n",
    "\n",
    "    # Write a pattern to extract numbers and decimals\n",
    "    def return_temp(string):\n",
    "        pattern = re.compile(r\"\\d+\\.\\d+\")\n",
    "        \n",
    "        # Search the text for matches\n",
    "        temp = re.match(pattern, string)\n",
    "        \n",
    "        # If a value is returned, use group(0) to return the found value\n",
    "        if temp is not None:\n",
    "            return float(temp.group(0))\n",
    "            \n",
    "    # Apply the function to the string column and take a look at both columns\n",
    "    df[\"string_val\"] = df[\"string\"].apply(lambda row: return_temp(row))\n",
    "    print(df[[\"string\", \"string_val\"]].head())\n",
    "\n",
    "(4) 計數表示(Word count representation)\n",
    "\n",
    "    # Initializing the vectorizer\n",
    "    from sklearn.feature_extraction.text import CountVectorizer\n",
    "    cv = CountVectorizer()\n",
    "\n",
    "    # Specifying the vectorizer\n",
    "    # min_df : minimum fraction of documents the word must occur in\n",
    "    # max_df : maximum fraction of documents the word can occur in\n",
    "    cv = CountVectorizer(min_df=0.1, max_df=0.9)\n",
    "\n",
    "    # Fitting and transforming the vectorizer\n",
    "    cv.fit(df['text_clean'])\n",
    "    cv_transformed = cv.transform(df['text_clean'])\n",
    "\n",
    "    # Transforming to toarray()\n",
    "    cv_transformed.toarray()\n",
    "\n",
    "    # Getting the features\n",
    "    feature_names = cv.get_feature_names()\n",
    "\n",
    "    # Create cv_df dataframe\n",
    "    cv_df = pd.DataFrame(cv_transformed.toarray(), columns=cv.get_feature_names()).add_prefix('Counts_')\n",
    "\n",
    "    # Updating DataFrame\n",
    "    df = pd.concat([df, cv_df], axis=1, sort=False)\n",
    "\n",
    "*Issue with word count representation:*\n",
    "\n",
    "Counts may be vary large for commom words which provide little value as a distinguishing feature.\n",
    " \n",
    "(5) tf/idf representation\n",
    "\n",
    "a. 向量化文字(Vectorizing text)\n",
    "\n",
    "- term frequency (tf)\n",
    "\n",
    "\n",
    "- inverse document frequency (idf)\n",
    "\n",
    "\n",
    "*TF-IDF = (count of word occurances / total words in document) / log(number of docs word is in / total number of docs)*\n",
    "\n",
    "b. 文字擷取套件: TfidfVectorizer\n",
    "\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "    # Max features and stopwords\n",
    "    (max_features : Maximum number of columns created from TF-IDF)\n",
    "    (stop_words : List of common words to omit e.g. \"and\", \"the\" etc.)\n",
    "    tv = TfidfVectorizer(max_features=100, stop_words='english')\n",
    "\n",
    "    # Fitting and transforming the text\n",
    "    tv_transformed = tv.fit_transform(df['text'])\n",
    "\n",
    "    # Putting it all together\n",
    "    tv_df = pd.DataFrame(tv_transformed.toarray(), columns=tv.get_feature_names()).add_prefix('TFIDF_') \n",
    "    df = pd.concat([df, tv_df], axis=1, sort=False)\n",
    "\n",
    "    # Inspecting the transforms\n",
    "    examine_row = tv_df.iloc[0]\n",
    "    print(examine_row.sort_values(ascending=False))\n",
    "\n",
    "    # Applying the vectorizer to new data\n",
    "    new_tv_transformed = tv.transform(new_df['text'])\n",
    "    new_tv_df = pd.DataFrame(new_tv_transformed.toarray(), columns=tv.get_feature_names()).add_prefix('TFIDF_')\n",
    "    new_df = pd.concat([new_df, new_tv_df], axis=1, sort=False)\n",
    "\n",
    "c. 使用 tf/idf 向量作文字分類(Text classification)\n",
    "\n",
    "i. Naive Bayes Classifier:\n",
    "\n",
    "- Features are independent\n",
    "\n",
    "\n",
    "- Efficiency in high-dimensional space\n",
    "\n",
    "\n",
    "ii. Example: \n",
    "\n",
    "      # Run the toarray() method on the tf/idf vector\n",
    "      # Split the dataset according to the class distribution of category\n",
    "      y = df[\"category\"]\n",
    "      X_train, X_test, y_train, y_test = train_test_split(tv_transformed.toarray(), y, stratify=y)\n",
    "\n",
    "      # Fit the model to the training data\n",
    "      nb.fit(X_train, y_train)\n",
    "\n",
    "      # Print out the model's accuracy\n",
    "      print(nb.score(X_test, y_test))\n",
    "      \n",
    "(6) 詞袋(Bag of words)與 N 元語法(N-grams)\n",
    "\n",
    "a. 詞袋(bag of words)\n",
    "\n",
    "- 一個沒有順序或文法的單詞集合\n",
    "\n",
    "\n",
    "b. N 元語法(N-grams)\n",
    "\n",
    "- 使用有序排列的單詞來代表有語義的文字\n",
    "\n",
    "\n",
    "Example: \n",
    "\n",
    "- bigrams: Sequences of two consecutive words\n",
    "\n",
    "\n",
    "- trigrams: Sequences of two consecutive words\n",
    "\n",
    "\n",
    "c. 使用 tf/idf 向量處理二元語法(bi-grams)\n",
    "\n",
    "    # ngram_range = (min, max): minimum and maximum length of n-grams\n",
    "    tv_bi_gram_vec = TfidfVectorizer(ngram_range = (2, 2))\n",
    "\n",
    "    # Fit and apply bigram vectorizer\n",
    "    tv_bi_gram = tv_bi_gram_vec.fit_transform(df['text'])\n",
    "\n",
    "    # Print the bigram features\n",
    "    print(tv_bi_gram_vec.get_feature_names())\n",
    "\n",
    "    # Create a DataFrame with the Counts features\n",
    "    tv_df = pd.DataFrame(tv_bi_gram.toarray(), columns=tv_bi_gram_vec.get_feature_names()).add_prefix('Counts_')\n",
    "    \n",
    "    # Finding common words\n",
    "    tv_sums = tv_df.sum()\n",
    "    print(tv_sums.sort_values(ascending=False)).head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
