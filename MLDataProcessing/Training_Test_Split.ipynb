{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 訓練與測試資料的處理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 訓練與測試資料的分佈(Train/test distributions)\n",
    "\n",
    "(1) 訓練與測試資料的分割:\n",
    "\n",
    "a. 分割訓練與測試資料的套件: train_test_split (預設值: 75% training set, 25% test set)\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "b. 單一種類/數值資料\n",
    "\n",
    "    train, test = train_test_split(X, y, test_size=測試資料的比例)\n",
    "\n",
    "c. 含兩個種類的資料\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=測試資料的比例)\n",
    "\n",
    "(2) 若訓練資料的分佈明顯不同於測試資料的分佈，會造成 ML 模型有較差的表現\n",
    "\n",
    "(3) 如何解決訓練與測試資料分佈不同的問題?\n",
    "\n",
    "Example: 100 samples, 50 class 1 and 50 class 2\n",
    "\n",
    "a. Training set: 80 samples\n",
    "\n",
    "- class 1: 70\n",
    "\n",
    "\n",
    "- class 2: 10\n",
    "\n",
    "\n",
    "b. Test set: 20 samples\n",
    "\n",
    "- class 1: 5\n",
    "\n",
    "\n",
    "- class 2: 15\n",
    "\n",
    "\n",
    "分層抽樣法(Stratified sampling): 使訓練和測試資料中的種類比例相同於總體資料中的種類比例\n",
    "\n",
    "    # Stratified sampling\n",
    "    X_train,X_test,y_train,y_test = train_test_split(X, y, stratify=y)\n",
    "\n",
    "a. Training set: 80 samples\n",
    "\n",
    "- class 1: 40\n",
    "\n",
    "\n",
    "- class 2: 40\n",
    "\n",
    "\n",
    "b. Test set: 20 samples\n",
    "\n",
    "- class 1: 10\n",
    "\n",
    "\n",
    "- class 2: 10\n",
    "\n",
    "\n",
    "(4) 不平衡種類(imbalanced classes)資料的處理\n",
    "\n",
    "- Categorical target variable should approximately have equal number observations/class\n",
    "\n",
    "\n",
    "- Large difference between the number of observations in each class $\\rightarrow$ misleading results\n",
    "\n",
    "\n",
    "Example: 100 samples, 80 class 1 and 20 class 2\n",
    "\n",
    "a. Training set: 75 samples\n",
    "\n",
    "- class 1: 60\n",
    "\n",
    "\n",
    "- class 2: 15\n",
    "\n",
    "\n",
    "b. Test set: 25 samples\n",
    "\n",
    "- class 1: 20\n",
    "\n",
    "\n",
    "- class 2: 5\n",
    "\n",
    "\n",
    "方法一: 分層抽樣法(Stratified sampling)\n",
    "     \n",
    "    # Create a data with all columns except categories\n",
    "    X = df.drop(\"categories\", axis=1)\n",
    "\n",
    "    # Create a categories labels dataset\n",
    "    y = df[[\"categories\"]]\n",
    "\n",
    "    # Stratified sampling for imbalanced class\n",
    "    X_train,X_test,y_train,y_test = train_test_split(X, y, stratify=y)\n",
    "\n",
    "    # 查看 labels 的數量\n",
    "    y[\"labels\"].value_counts()\n",
    "    y_train[\"labels\"].value_counts()\n",
    "    y_test[\"labels\"].value_counts()\n",
    "\n",
    "\n",
    "方法二: 重新採樣(resampling) $\\rightarrow$ 試著平衡不同種類的數量\n",
    "\n",
    "- majority class (class A)\n",
    "\n",
    "\n",
    "- minority class (class B)\n",
    "\n",
    "\n",
    "- target class\n",
    "\n",
    "\n",
    "套件: sklearn.utils.resample(m, n_samples=len(n))\n",
    "\n",
    "a. Oversample minority class (class B)\n",
    "\n",
    "    # Upsample minority and combine with majority\n",
    "    data_upsampled = resample(classB, replace=True, n_samples=len(classA), random_state=123)\n",
    "    upsampled = pd.concat([classA, data_upsampled])\n",
    "\n",
    "    # Upsampled feature matrix and target array\n",
    "    X_train_up = upsampled.drop('targetclass', axis=1)\n",
    "    y_train_up = upsampled['targetclass']\n",
    "    \n",
    "b. Undersample majority class (class A)\n",
    "\n",
    "    # Downsample majority and combine with minority\n",
    "    data_downsampled = resample(classA, replace = False,  n_samples = len(classB), random_state = 123)\n",
    "    downsampled = pd.concat([data_downsampled, classB])\n",
    "\n",
    "    # Downsampled feature matrix and target array\n",
    "    X_train_down = downsampled.drop('targetclass', axis=1)\n",
    "    y_train_down = downsampled['targetclass']\n",
    "\n",
    "**注意事項: 分割訓練與測試資料之後再重新採樣(resampling)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 訓練與測試資料分佈的視覺化\n",
    "\n",
    "(1) Matrix of distributions and scatterplots:\n",
    "\n",
    "    sns.pairplot()\n",
    "\n",
    "Example: 訓練與測試資料分佈的視覺化\n",
    "\n",
    "    # Create subset: data_subset\n",
    "    data_subset = data[['A','B','class']]\n",
    "\n",
    "    # Create train and test sets\n",
    "    trainingSet, testSet = train_test_split(data_subset, test_size=0.2, random_state=123)\n",
    "\n",
    "    # Examine pairplots\n",
    "    plt.figure()\n",
    "    sns.pairplot(trainingSet, hue='class', palette='RdBu')\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure()\n",
    "    sns.pairplot(testSet, hue='class', palette='RdBu')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 不平衡種類(imbalanced classes)資料的模型評估(model evaluation)\n",
    "\n",
    "(1) Confusion matrix\n",
    "\n",
    "- It shows the number of correctly and incorrectly classified observations in each class\n",
    "\n",
    "\n",
    "(2) Performance metrics\n",
    "\n",
    "- accuracy \n",
    "\n",
    "\n",
    "- precision \n",
    "\n",
    "\n",
    "- recall/sensitivity \n",
    "\n",
    "\n",
    "- specificity \n",
    "\n",
    "\n",
    "- F1 score\n",
    "\n",
    "\n",
    "(3) Functions\n",
    "\n",
    "- confusion matrix: sklearn.metrics.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "\n",
    "- precision: sklearn.metrics.precision_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "- recall: sklearn.metrics.recall_score(y_test, y_pred) \n",
    "\n",
    "\n",
    "- f1 score: sklearn.metrics.f1_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "**Imbalanced class metrics**\n",
    "    \n",
    "    # Import\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "    # Instantiate, fit, predict\n",
    "    lr = LogisticRegression(solver='liblinear')\n",
    "    lr.fit(X_train, y_train)\n",
    "    y_pred = lr.predict(X_test)\n",
    "\n",
    "    # Print evaluation metrics\n",
    "    print(\"Confusion matrix:\\n {}\".format(confusion_matrix(y_test, y_pred)))\n",
    "    print(\"Accuracy: {}\".format(accuracy_score(y_test, y_pred)))\n",
    "    print(\"Precision: {}\".format(precision_score(y_test, y_pred)))\n",
    "    print(\"Recall: {}\".format(recall_score(y_test, y_pred)))\n",
    "    print(\"F1: {}\".format(f1_score(y_test, y_pred)))\n",
    "\n",
    "**Using resampling techniques**\n",
    "   \n",
    "a. Oversample minority class\n",
    "\n",
    "    # Instantiate logistic regression, fit, predict\n",
    "    loan_lr_up = LogisticRegression(solver='liblinear')\n",
    "    loan_lr_up.fit(X_train_up, y_train_up)\n",
    "    upsampled_y_pred = loan_lr_up.predict(X_test)\n",
    "\n",
    "    # Print evaluation metrics\n",
    "    print(\"Confusion matrix:\\n {}\".format(confusion_matrix(y_test, upsampled_y_pred)))\n",
    "    print(\"Accuracy: {}\".format(accuracy_score(y_test, upsampled_y_pred)))\n",
    "    print(\"Precision: {}\".format(precision_score(y_test, upsampled_y_pred)))\n",
    "    print(\"Recall: {}\".format(recall_score(y_test, upsampled_y_pred)))\n",
    "    print(\"F1: {}\".format(f1_score(y_test, upsampled_y_pred)))\n",
    "\n",
    "b. Undersample majority class\n",
    "\n",
    "    # Instantiate, fit, predict\n",
    "    loan_lr_down = LogisticRegression(solver='liblinear')\n",
    "    loan_lr_down.fit(X_train_down, y_train_down)\n",
    "    downsampled_y_pred = loan_lr_down.predict(X_test)\n",
    "\n",
    "    # Print evaluation metrics\n",
    "    print(\"Confusion matrix:\\n {}\".format(confusion_matrix(y_test, downsampled_y_pred)))\n",
    "    print(\"Accuracy: {}\".format(accuracy_score(y_test, downsampled_y_pred)))\n",
    "    print(\"Precision: {}\".format(precision_score(y_test, downsampled_y_pred)))\n",
    "    print(\"Recall: {}\".format(recall_score(y_test, downsampled_y_pred)))   \n",
    "    print(\"F1: {}\".format(f1_score(y_test, downsampled_y_pred)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
