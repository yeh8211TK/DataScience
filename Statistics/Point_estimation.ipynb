{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 推論統計學: 利用樣本統計量及其抽樣分配來推估母體的特性\n",
    "\n",
    "#### 1. 母數統計學(parametric statistics): 母體為常態或樣本為大樣本的推論統計學\n",
    "\n",
    "#### 2. 無母數統計學(non-parametric statistics): 母體分配不明或樣本為小樣本的推論統計學\n",
    "\n",
    "### 估計的目的:\n",
    "\n",
    "#### 1. 統計估計(statistical estimation): 利用樣本統計量去推估母體參數的方法\n",
    "\n",
    "- 點估計(point estimation)\n",
    "\n",
    "  母體平均數 $\\mu$ 的估計方法: 樣本平均數 $\\mu$ (最常用)、樣本中位數\n",
    "\n",
    "  母體變異數 $\\sigma^{2}$ 的估計方法: 以樣本變異數 $s^{2}=\\frac{\\sum_{i=1}^{n}\\left ( x_{i}-\\bar{x} \\right )^{2}}{n-1}$ 最為常用，因為它具有**不偏性(unbiasedness)**\n",
    "\n",
    "\n",
    "- 區間估計(interval estimation): 利用樣本統計量估計出母體參數所在的一個區間\n",
    "\n",
    "#### 2. 假設檢定(hypothesis testing)\n",
    "\n",
    "### 點估計的方法:\n",
    "\n",
    "#### 1. 動差估計法(method of moments estimation, MME)\n",
    "\n",
    "(1) 動差估計法(method of moments estimation)的概念: 母體動差=樣本動差\n",
    "\n",
    "\n",
    "$$E\\left ( x^{k} \\right )=\\frac{\\sum_{i=1}^{n}x_{i}^{k}}{n}$$\n",
    "\n",
    "(2) (弱)大數法則(law of large numbers): 重複試驗產生一組均為獨立且有相同分佈的隨機樣本 $X_{1}, X_{2},..., X_{n}$，當試驗次數 $n\\rightarrow \\infty$時，則樣本平均數會以機率模式趨近期望值。\n",
    "\n",
    "\n",
    "$$\\frac{X_{1}+X_{2}+...X_{n}}{n}\\xrightarrow[n\\rightarrow \\infty ]{p} E\\left ( X \\right )$$\n",
    "\n",
    "(3) k 階動差(moment)的概念: 以樣本動差估計母體動差 (使用 X 之 k 次方的樣本平均數來估計 X 之 k 次方的期望值)\n",
    "\n",
    "k 階母體動差:\n",
    "\n",
    "\n",
    "$$\\mu_{k}^{'}=E\\left ( x^{k} \\right )=\\left\\{\\begin{matrix}\n",
    "\\sum_{x}x^{k}\\cdot P\\left ( x \\right )\\ \\ \\ \\ \\ \\ (離散)\\\\ \n",
    "\\int_{-\\infty }^{\\infty }x^{k}\\cdot f\\left ( x \\right )dx\\ \\  (連續)\n",
    "\\end{matrix}\\right.$$\n",
    "\n",
    "k 階樣本動差:\n",
    "\n",
    "\n",
    "$$m_{k}^{'}=\\frac{\\sum_{i=1}^{n}x_{i}^{k}}{n}$$\n",
    "\n",
    "動差估計量(moment estimator): 使用動差法(method of moments)所得到的估計量\n",
    "\n",
    "(4) 常用的動差法:\n",
    "\n",
    "- 1 階動差:\n",
    "\n",
    "\n",
    "$$\\mu =\\mu_{1}^{'}=m_{1}^{'}=\\frac{1}{n}\\sum_{i=1}^{n}x_{i}=\\bar{x}$$\n",
    "\n",
    "- 2 階動差:\n",
    "\n",
    "\n",
    "$$\\sigma^{2}=\\frac{\\sum_{i=1}^{n}x_{i}^{2}}{n}-\\bar{x}^{2}=\\frac{1}{n}\\sum_{i=1}^{n}\\left (x_{i}-\\bar{x}\\right )^{2}$$\n",
    "\n",
    "(5) 各種分配的動差估計(正態分配、二項分配、Poisson 分配)\n",
    "\n",
    "a. **正態分配**: 設 $x_{1}, x_{2}, ...,x_{n}\\overset{i.i.d}{\\rightarrow}N(\\mu ,\\sigma^{2})$，用動差法估計 $\\mu$ 與 $\\sigma^{2}$\n",
    "\n",
    "- 1 階動差:\n",
    "\n",
    "\n",
    "$$E(x)=\\hat{\\mu }=\\frac{1}{n}\\sum_{i=1}^{n}x_{i}=\\bar{x}$$\n",
    "\n",
    "- 2 階動差:\n",
    "\n",
    "\n",
    "$$E(x^{2})=E(x^{2})-[E(x)]^{2}+[E(x)]^{2}=\\sigma^{2}+\\mu^{2}$$\n",
    "\n",
    "\n",
    "$$\\hat{\\sigma}^{2}=\\frac{1}{n}\\sum_{i=1}^{n}x_{i}^{2}-\\bar{x}^{2}=\\frac{1}{n}\\left (\\sum_{i=1}^{n}x_{i}^{2}-n\\bar{x}^{2} \\right )=\\frac{1}{n}\\sum_{i=1}^{n}\\left (x_{i}-\\bar{x} \\right )^{2}$$\n",
    "\n",
    "[Note]\n",
    "   \n",
    "   \n",
    "$$\\sum_{i=1}^{n}\\left (x_{i}-\\bar{x}\\right)^{2}=\\sum_{i=1}^{n}\\left(x_{i}^{2}-2x_{i}\\bar{x}+\\bar{x}^{2} \\right)=\\sum_{i=1}^{n}x_{i}^{2}-2\\bar{x}\\sum_{i=1}^{n}x_{i}+\\sum_{i=1}^{n}\\bar{x}^{2}=\\sum_{i=1}^{n}x_{i}^{2}-2\\bar{x}n\\bar{x}+n\\bar{x}^{2}=\\sum_{i=1}^{n}x_{i}^{2}-n\\bar{x}^{2}$$\n",
    "\n",
    "b. **二項分配**: 一組隨機樣本 $x_{1}, x_{2}, ...,x_{k}$ 來自二項分配 $b(x;n,p)$，用動差法估計 p\n",
    "\n",
    "\n",
    "$$\\mu = E(x)=np,\\ \\\n",
    "m_{1}^{'}=\\frac{x_{1}+x_{1}+...+x_{k}}{k}=\\bar{x_{k}}\n",
    "\\Rightarrow \\hat{n}\\hat{p}=\\bar{x_{k}}$$\n",
    "\n",
    "\n",
    "$$\\sigma^{2}=Var(x)=\\hat{n}\\hat{p}\\left ( 1-\\hat{p} \\right )=\\frac{1}{k}\\sum_{i=1}^{k}x_{i}^{2}-\\bar{x}^{2}$$\n",
    "\n",
    "\n",
    "$$\\Rightarrow \\bar{x_{k}}\\left ( 1-\\hat{p} \\right )=\\frac{1}{k}\\sum_{i=1}^{k}x_{i}^{2}-\\bar{x}_{k}^{2} \\Rightarrow \\hat{p}=1-\\frac{\\sum_{i=1}^{k}x_{i}^{2}-k\\bar{x}_{k}^{2}}{k\\bar{x}_{k}}$$\n",
    "\n",
    "c. **Poisson 分配**: 設 $x_{1}, x_{2}, ...,x_{n}\\overset{i.i.d}{\\rightarrow}P(x)$，其中機率質量函數(probability mass function)為 $P(x)=e^{-\\lambda}\\lambda ^{x}/x!$\n",
    "\n",
    "\n",
    "$$E(x)=\\lambda \\Rightarrow \\hat{\\lambda }=\\frac{1}{n}\\sum_{i=1}^{n}x_{i}$$\n",
    "\n",
    "\n",
    "$$Var(x)=\\lambda \\Rightarrow \\hat{\\lambda }=\\frac{1}{n}\\sum_{i=1}^{n}\\left (x_{i}-\\bar{x} \\right )^{2}$$\n",
    "\n",
    "**$\\Rightarrow$ 動差估計法不唯一**\n",
    "\n",
    "#### 2. 最大概似法(maximum likelihood estimation, MLE)\n",
    "\n",
    "(1) 概念: \n",
    "\n",
    "若從母體抽出一組隨機樣本，而母體參數 $\\theta$ 是我們想要研究的對象，若能找到一個估計值 $\\hat{\\theta}$，可以使這組樣本發生的可能性為最大，則此估計值 $\\hat{\\theta}$ 稱為 $\\theta$ 之最大概似估計值(Maximum Likelihood Estimator, MLE)\n",
    "\n",
    "(2) 概似函數(likelihood function):\n",
    "\n",
    "假設$(X_{1}, X_{2},...,X_{n})$ 為抽自母體 $f(X;\\theta)$ 的一組隨機樣本，則其概似函數(likelihood function)定義為這 n 個隨機變數的聯合機率分配 $L(\\theta)=f(X_{1}, X_{2},..., X_{n};\\theta)$\n",
    "\n",
    "\n",
    "$$L(\\theta)=f(X_{1}, X_{2},..., X_{n};\\theta)=f(X_{1};\\theta)\\ f(X_{2};\\theta)\\cdot \\cdot \\cdot f(X_{n};\\theta)=\\prod_{i=1}^{n}f(X_{i};\\theta)$$\n",
    "\n",
    "(3) 尋找最大概似函數的步驟:\n",
    "\n",
    "i. 建立 $L(\\theta)=f(X_{1}, X_{2},..., X_{n};\\theta)$\n",
    "\n",
    "ii. 取對數 $\\text{ln}\\ L(\\theta)=\\text{ln}\\ f(X_{1}, X_{2},..., X_{n};\\theta)$\n",
    "\n",
    "iii. 求一階導數並令為零: $\\frac{d\\ \\text{ln} L\\left ( \\theta  \\right )}{d \\theta }=0$\n",
    "\n",
    "iv. 求二階導數並判斷是否為極大值: $\\frac{d^{2}\\ \\text{ln} L\\left ( \\theta  \\right )}{d^{2} \\theta }<0$\n",
    "\n",
    "(4) 最大概似法估計參數:\n",
    "\n",
    "a. **幾何分配**: 隨機變數 $X_{i}\\ (i={1,2,...,n})$ 服從幾何分配 $f\\left ( x_{i} \\right )=p\\left ( 1-p \\right )^{x_{i}-1}$，估計參數 $p$\n",
    "\n",
    "\n",
    "$$\\begin{equation} \n",
    "\\begin{aligned}\n",
    "& L\\left ( p \\right )=f\\left ( x_{1}, x_{2},...,x_{n};p \\right )=p\\left ( 1-p \\right )^{x_{1}-1}\\cdot p\\left ( 1-p \\right )^{x_{2}-1}\\cdot \\cdot \\cdot p\\left ( 1-p \\right )^{x_{n}-1}=p^{n}\\left ( 1-p \\right )^{\\sum_{i=1}^{n}x_{i}-n}\\\\\n",
    "&\\Rightarrow \\text{ln}L\\left ( p \\right )=n\\text{ln}p+\\left ( \\sum_{i=1}^{n}x_{i}-n \\right )\\text{ln}\\left ( 1-p \\right )\\\\\n",
    "& \\frac{\\mathrm{d} }{\\mathrm{d} p}\\text{ln}L\\left ( p \\right )=\\frac{n}{p}-\\left ( \\sum_{i=1}^{n}x_{i}-n \\right )\\frac{1}{1-p}=0\\\\\n",
    "&\\Rightarrow p=\\frac{n}{\\sum_{i=1}^{n}x_{i}}=\\frac{1}{\\bar{x}}\\\\\n",
    "&\\frac{\\mathrm{d^{2}} }{\\mathrm{d} p^{2}}\\text{ln}L\\left ( p \\right )\\big{|}_{p=\\frac{1}{\\bar{x}}}=-\\frac{n}{p^{2}}-\\left ( \\sum_{i=1}^{n}x_{i}-n \\right )\\frac{1}{\\left ( 1-p \\right )^{2}}\\big{|}_{p=\\frac{1}{\\bar{x}}}=-\\frac{n\\bar{x}^{3}}{\\bar{x}-1}<0\n",
    "\\end{aligned} \t\n",
    "\\end{equation}$$\n",
    "\n",
    "b. **Poisson 分配**: 隨機變數 $X_{i}\\ (i={1,2,...,n})$ 服從 Poisson 分配 $f(x_{i})=e^{-\\lambda}\\lambda ^{x}/x!$，估計參數 $\\lambda$\n",
    "\n",
    "\n",
    "$$\\begin{equation} \n",
    "\\begin{aligned}\n",
    "& L\\left ( p \\right )=f\\left ( x_{1}, x_{2},...,x_{n};p \\right )=\\frac{e^{-n\\lambda }\\cdot \\lambda ^{x_{1}+x_{2}+\\cdot \\cdot \\cdot x_{n}}}{x_{1}!x_{2}!\\cdot \\cdot \\cdot x_{n}!}=\\frac{e^{-n\\lambda} \\cdot \\lambda^{\\sum_{i=1}^{n}x_{i}}}{\\prod_{i=1}^{n}x_{i}!}\\\\\n",
    "&\\Rightarrow \\text{ln}L\\left ( \\lambda  \\right )=-n\\lambda+\\left (\\sum_{i=1}^{n}x_{i}\\right )\\cdot \\text{ln}\\lambda-\\text{ln}\\left ( \\prod_{i=1}^{n}x_{i}! \\right )\\\\\n",
    "& \\frac{\\mathrm{d} }{\\mathrm{d} \\lambda}\\text{ln}L\\left ( \\lambda  \\right )=-n+\\frac{1}{\\lambda }\\sum_{i=1}^{n}x_{i}=0\\\\\n",
    "& \\Rightarrow \\lambda=\\frac{1}{n}\\left ( \\sum_{i=1}^{n}x_{i} \\right )=\\bar{x}\\\\\n",
    "& \\frac{\\mathrm{d^{2}}}{\\mathrm{d} \\lambda^{2}}\\text{ln}L\\left ( \\lambda \\right )\\big{|}_{\\lambda=\\bar{x}}=-\\frac{1}{\\lambda ^{2}}\\left ( \\sum_{i=1}^{n}x_{i} \\right ) \\big{|}_{\\lambda=\\bar{x}}=-\\frac{n\\bar{x}}{\\bar{x}^{2}}=-\\frac{n}{\\bar{x}}<0\n",
    "\\end{aligned} \t\n",
    "\\end{equation}$$\n",
    "\n",
    "c. **均勻分配**: 隨機變數 $X_{i}\\ (i={1,2,...,n})$ 為分布於 $[0, \\theta]$ 的均勻分配 $f(x_{i})=1/\\theta$，估計參數 $\\theta$\n",
    "\n",
    "\n",
    "$$\\begin{equation} \n",
    "\\begin{aligned}\n",
    "& L\\left ( \\theta \\right )=f\\left ( x_{1}, x_{2},...,x_{n};\\theta \\right )=\\frac{1}{\\theta^{n}}\\\\\n",
    "& \\text{ln}L\\left ( \\theta \\right)=-n\\cdot \\text{ln}\\theta\\\\\n",
    "& \\Rightarrow \\frac{\\mathrm{d} }{\\mathrm{d} \\theta }\\text{ln}L\\left ( \\theta \\right )=-\\frac{n}{\\theta }\\\\\n",
    "& \\because \\ L\\left ( \\theta \\right )\\ \\text{為}\\ \\theta \\ \\text{的遞減函數}\\\\\n",
    "& \\therefore \\ \\theta \\ \\text{以}\\ max(x_{1}, x_{2},...,x_{n}) \\ \\text{可得到最大}\n",
    "\\end{aligned} \t\n",
    "\\end{equation}$$\n",
    "\n",
    "#### 3. 貝氏估計法(method of Bayes)\n",
    "\n",
    "(1) 條件機率與貝式定理:\n",
    "\n",
    "\n",
    "$$\\begin{equation} \n",
    "\\begin{aligned}\n",
    "P(A|B)&=\\frac{P(A\\bigcap B)}{P(B)}\\ \\ (P(B)已知)\\\\\n",
    "&=\\frac{P(A)\\cdot P(B|A)}{P(A\\bigcap B)+P(A^{'}\\bigcap B)}=\\frac{P(A)\\cdot P(B|A)}{P(A)\\cdot P(B|A)+P(A^{'})\\cdot P(B|A^{'})}\\ \\ (P(B)未知)\n",
    "\\end{aligned} \t\n",
    "\\end{equation}$$\n",
    "\n",
    "(2) 貝式估計:\n",
    "\n",
    "事前機率(prior probability) $\\overset{修正}{\\rightarrow}$ 事後機率(posterior probability)\n",
    "\n",
    "說明:\n",
    "\n",
    "(i) 要對參數 $\\theta$ 進行估計，首先假設一個事前機率，它可視為主觀的機率，也可以依據過去的資料而做出較為客觀的判斷\n",
    "\n",
    "(ii) 取樣後，根據所得之觀測結果，修正對 $\\theta$ 之機率的看法，如此得到事後機率\n",
    "\n",
    "### 點估計的評估標準:\n",
    "\n",
    "#### 1. 不偏性 (unbiasedness)\n",
    "\n",
    "定義: 若 $E\\left ( \\hat{\\theta } \\right )=\\theta $，則稱估計量 $\\hat{\\theta }$ 為 $\\theta$ 的不偏估計量\n",
    "\n",
    "\n",
    "- 母體平均數 $\\mu$ 之不偏估計量\n",
    "\n",
    "  假設樣本資料 $x_{1}, x_{2},..., x_{n}$ 是從一個平均數 $\\mu$ 之母體中隨機抽樣而來且 $\\bar{x}=(x_{1}+x_{2}+...+x_{n})/n$，則 $\\bar{x}$ 是 $\\mu$ 的不偏估計量\n",
    "\n",
    "\n",
    "$$E(\\bar{x})=E(\\frac{x_{1}+x_{2}+...+x_{n}}{n})=\\frac{1}{n}E(x_{1}+x_{2}+...+x_{n})=\\frac{1}{n}[E(x_{1})+E(x_{2})+...+E(x_{n})]=\\frac{1}{n}\\cdot n\\mu=\\mu$$\n",
    "\n",
    "- 母體變異數 $\\sigma^{2}$ 之不偏估計量\n",
    "\n",
    "  說明: $s^{2}=[\\sum_{i=1}^{n}\\left ( x_{i} -\\bar{x}\\right )^{2}]/(n-1)$ 是母體變異數 $\\sigma^{2}$ 的不偏估計量\n",
    "\n",
    "\n",
    "$$\\begin{equation} \n",
    "\\begin{aligned} \n",
    "E(s^{2})&= E\\left ( \\frac{\\sum_{i=1}^{n}\\left ( x_{i} -\\bar{x}\\right )^{2}}{n-1} \\right )=\\frac{1}{n-1}\\cdot E\\left (\\sum_{i=1}^{n}\\left ( x_{i} -\\bar{x}\\right )^{2}\\right )=\\frac{1}{n-1}\\cdot E\\left (\\sum_{i=1}^{n}\\left [ (x_{i}-\\mu) -(\\bar{x}-\\mu)\\right ]^{2}\\right )\\\\ \n",
    "&=\\frac{1}{n-1}\\cdot E\\left (\\sum_{i=1}^{n}(x_{i}-\\mu)^{2}-2\\sum_{i=1}^{n}(x_{i}-\\mu)(\\bar{x}-\\mu)+\\sum_{i=1}^{n}(\\bar{x}-\\mu)^{2}\\right )\\\\\n",
    "&=\\frac{1}{n-1}\\cdot E\\left (\\sum_{i=1}^{n}(x_{i}-\\mu)^{2}-2(\\bar{x}-\\mu)\\sum_{i=1}^{n}(x_{i}-\\mu)+n(\\bar{x}-\\mu)^{2}\\right )\\\\\n",
    "&=\\frac{1}{n-1}\\cdot E\\left (\\sum_{i=1}^{n}(x_{i}-\\mu)^{2}-2n(\\bar{x}-\\mu)^{2}+n(\\bar{x}-\\mu)^{2}\\right )\\\\\n",
    "&=\\frac{1}{n-1}\\cdot E\\left (\\sum_{i=1}^{n}(x_{i}-\\mu)^{2}-n(\\bar{x}-\\mu)^{2}\\right )=\\frac{1}{n-1}\\cdot \\left (\\sum_{i=1}^{n}E(x_{i}-\\mu)^{2}-nE(\\bar{x}-\\mu)^{2}\\right )\\\\\n",
    "&=\\frac{1}{n-1}\\cdot \\left (\\sum_{i=1}^{n}\\sigma_{x_{i}}^{2}-n\\sigma_{\\bar{x}}^{2}\\right )=\\frac{1}{n-1}\\cdot \\left ( n\\sigma ^{2}-\\sigma ^{2} \\right )=\\sigma ^{2}\\\\\n",
    "& \\left (\\because\\  \\sigma_{x_{i}}^{2}(i=1,2,...,n)=\\sigma^{2},\\ \\sigma_{\\bar{x}}^{2}=\\sigma^{2}/n  \\right )\n",
    "\\end{aligned} \t\n",
    "\\end{equation}$$\n",
    "\n",
    "#### 2. 有效性 (efficiency)\n",
    "\n",
    "說明 1: 若 $E\\left ( \\hat{\\theta}_{1} \\right )=E\\left ( \\hat{\\theta}_{2} \\right )=\\theta $，則稱估計量 $\\hat{\\theta }_{1}$ 與 $\\hat{\\theta }_{2}$ 都是 $\\theta$ 的不偏估計量。在估計 $\\theta$ 時，當 $Var\\left ( \\hat{\\theta}_{1} \\right ) < Var\\left ( \\hat{\\theta}_{2} \\right )$，則估計量 $\\hat{\\theta}_{1}$ 相對於 $\\hat{\\theta}_{2}$ 有效\n",
    "\n",
    "說明 2: 假設估計量 $\\theta_{1}$ 是 $\\theta$ 的估計量:\n",
    "\n",
    "  (1) $E\\left ( \\hat{\\theta}_{1} \\right )=\\theta$\n",
    "  \n",
    "  (2) $Var\\left ( \\hat{\\theta}_{1}\\right)$ 小於任何不偏估計式之變異數\n",
    "\n",
    "則稱 $\\hat{\\theta}_{1}$ 為**最小變異不偏估計式(Minimum-Variance Unbiased Estimator, MVUE)**\n",
    "\n",
    "#### 3. 一致性 (consistency)\n",
    "\n",
    "定義: 當樣本數增大時，估計值與母體參數的差異會越來越小，當樣本數趨近於無限大時，差異會趨近於零\n",
    "\n",
    "\n",
    "$$\\forall \\epsilon > 0,\\ \\lim_{n\\rightarrow \\infty }P\\left ( \\left | \\hat{\\Theta}_{n}-\\Theta  \\right |>\\epsilon  \\right )=0\\ \\ \\textbf{or}\\ \\lim_{n\\rightarrow \\infty }Var\\left (\\hat{\\Theta}_{n}\\right )=0$$\n",
    "\n",
    "- 樣本平均數的一致性估計\n",
    "\n",
    "  說明: $\\bar{x}$ 是 $\\mu$ 的一致估計量\n",
    "\n",
    "\n",
    "$$\\begin{equation} \n",
    "\\begin{aligned}\n",
    "& \\bar{x}=\\frac{\\sum_{i=1}^{n}x_{i}}{n}\\\\\n",
    "\\Rightarrow & Var\\left ( \\bar{x} \\right )=Var\\left [ \\frac{\\sum_{i=1}^{n}x_{i}}{n} \\right ]=\\frac{n\\sigma^{2}}{n^{2}}=\\frac{\\sigma^{2}}{n}\\\\\n",
    "\\Rightarrow & Var\\left ( \\bar{x} \\right )=\\lim_{n\\rightarrow \\infty}\\frac{\\sigma^{2}}{n}=0\n",
    "\\end{aligned} \t\n",
    "\\end{equation}$$\n",
    "\n",
    "- 樣本變異數的一致性估計\n",
    "\n",
    "  說明: $s^{2}=[\\sum_{i=1}^{n}\\left ( x_{i} -\\bar{x}\\right )^{2}]/(n-1)$ 是 $\\sigma^{2}$ 的一致估計量\n",
    "\n",
    "  已知 $\\chi_{n-1}^{2}$ ~ $\\sum_{i=1}^{n}\\left ( x_{i} -\\bar{x}\\right )^{2}/\\sigma^{2}$, $E\\left ( \\chi_{n-1}^{2} \\right )=n-1$ 和 $Var\\left ( \\chi_{n-1}^{2} \\right )=2(n-1)$\n",
    "\n",
    "\n",
    "$$\\begin{equation} \n",
    "\\begin{aligned}\n",
    "&Var\\left [ \\frac{\\left ( n-1 \\right )s^{2}}{\\sigma^{2}} \\right ]=Var\\left ( \\chi_{n-1}^{2} \\right )\\\\\n",
    "\\Rightarrow &\\frac{\\left ( n-1 \\right )^{2}}{\\sigma^{4}}Var\\left (s^{2} \\right)=2\\left ( n-1 \\right )\\\\\n",
    "\\Rightarrow &Var\\left (s^{2} \\right)=\\frac{2\\sigma^{4}}{\\left ( n-1 \\right )}\\\\\n",
    "\\Rightarrow &\\lim_{n\\rightarrow \\infty}Var\\left (s^{2} \\right)=\\lim_{n\\rightarrow \\infty}\\frac{2\\sigma^{4}}{\\left ( n-1 \\right )}=0\n",
    "\\end{aligned}\\\\\n",
    "\\end{equation}$$\n",
    "\n",
    "#### 4. 充分性 (sufficiency)\n",
    "\n",
    "定義: 若點估計式 $\\hat{\\theta}$ 能充分表達出樣本資料中有關母體參數的資訊 $\\theta$，則 $\\hat{\\theta}$ 稱為 $\\theta$ 之充分估計量(sufficient estimator)\n",
    "\n",
    "數學描述:\n",
    "\n",
    "設 $X_{1}, X_{2},..., X_{n}$ 為一組描述母體參數 $\\theta$ 之隨機樣本，有一個估計量為 $Y(X_{1}, X_{2},..., X_{n})$，若條件機率 $P(X_{1}=x_{1}, X_{2}=x_{2},..., X_{n}=x_{n}|Y=y; \\theta)$ 與 $\\theta$ 無關，則稱 $Y(X_{1}, X_{2},..., X_{n})$ 是 $\\theta$ 的充分估計量\n",
    "\n",
    "例子:\n",
    "\n",
    "設 $X_{1}, X_{2},..., X_{n}$ 為 n 次 Bernoulli 試驗的結果，\n",
    "\n",
    "$$X_{i}=\\left\\{\\begin{matrix}\n",
    "1, \\text{第 i 次實驗成功(機率為 p)}\\\\ \n",
    "0, \\text{第 i 次實驗失敗(機率為 q)}\n",
    "\\end{matrix}\\right.$$\n",
    "\n",
    "則 $Y=\\sum_{i=1}^{n}X_{i}$ 為 $p$ 的充分估計量。\n",
    "\n",
    "$$P(X_{1}=x_{1}, X_{2}=x_{2},..., X_{n}=x_{n}|Y=y)=\\frac{P(X_{1}=x_{1}, X_{2}=x_{2},..., X_{n}=x_{n}, Y=y)}{P(Y=y)}=\\frac{p^{y}q^{n-y}}{C_{y}^{n}p^{y}q^{n-y}}=\\frac{1}{C_{y}^{n}}$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
