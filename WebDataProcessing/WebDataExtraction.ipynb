{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 一、網路資料擷取的方法\n",
    "\n",
    "- 串接目的網站提供的 API\n",
    "\n",
    "\n",
    "- 網路爬蟲(Web scraping)\n",
    "\n",
    "  It transforms the unstructured data (HTML format) on the web into structured data (database or spreadsheet)\n",
    "  \n",
    "  \n",
    "- 使用 import.io (a non-programming way)\n",
    "\n",
    "  It provides a GUI driven interface to perform all basic web scraping operations.\n",
    "\n",
    "\n",
    "### 二、爬取網路資料的 Python 模組\n",
    "\n",
    "- **urllib2** (python 2)/ **urllib.request** (python 3)/ **requests**: 用來解析 URL\n",
    "\n",
    "\n",
    "- **BeautifulSoup**: 用來取得網頁的資訊 (tables, lists, paragraph...)\n",
    "\n",
    "\n",
    "- **Selenium**: 以自動化的方式來取得網頁的資訊\n",
    "\n",
    "\n",
    "### 三、Python’s Requests Library\n",
    "\n",
    "較詳細的介紹可參考此篇文章: [Python’s Requests Library (Guide)](https://realpython.com/python-requests/)\n",
    "\n",
    "#### 1. HTTP GET method\n",
    "\n",
    "- 讀取網頁原始碼\n",
    "\n",
    "      html = requests.get('url')\n",
    "      \n",
    "      html.encoding = \"utf-8\"\n",
    "      \n",
    "      if html.status_code == requests.codes.ok:\n",
    "      \n",
    "          print(html.text)\n",
    "\n",
    "\n",
    "- 在 URL 加入參數進行查詢\n",
    "\n",
    "      payload = {'key1': value1, 'key2': value2, ...}\n",
    "\n",
    "      html = requests.get('url', params=payload)\n",
    "      \n",
    "      \n",
    "- 設定 HTTP Headers\n",
    "\n",
    "      hearders:{\n",
    "          'user-agent': ...,\n",
    "          ...\n",
    "      }\n",
    "      \n",
    "      html = requests.get('url', headers=headers)\n",
    "\n",
    "\n",
    "#### 2. HTTP POST method\n",
    "\n",
    "- 將查詢參數放入 HTTP Body 來向網站發出請求\n",
    "\n",
    "      payload = {'key1': value1, 'key2': value2, ...}\n",
    "\n",
    "      html = requests.post('url', data=payload)\n",
    "\n",
    "      \n",
    "#### 3. Cookie 與 Session\n",
    "\n",
    "- 建立 session\n",
    "\n",
    "      rs = requests.Session()\n",
    "\n",
    "\n",
    "- 使用 session 請求，將使用者資訊儲存在 server 端\n",
    "\n",
    "      payload = {'key1': value1, 'key2': value2, ...}\n",
    "\n",
    "      hearders:{\n",
    "          'user-agent': ...,\n",
    "          ...\n",
    "      }\n",
    "      \n",
    "      rs.post('url_1', data=payload, headers=headers)\n",
    "      \n",
    "      \n",
    "- 用已建立的 session 來儲存 cookie，並使用此 cookie 對同一網站的不同頁面發出請求\n",
    "\n",
    "      res = rs.get('url_2', headers=headers)\n",
    "\n",
    "\n",
    "### 四、網頁解析 - BeautifulSoup\n",
    "\n",
    "#### 1. 匯入模組\n",
    "\n",
    "- Import the library used to query a website\n",
    "\n",
    "      import urllib2 (python 2) / urllib.request (python 3) / requests\n",
    "\n",
    "\n",
    "- Specify the url\n",
    "\n",
    "      url = ...\n",
    "\n",
    "\n",
    "- Query the website and return the html to the variable 'page'\n",
    "\n",
    "      page = urllib2.urlopen(url) / urllib.request.urlopen(url) / requests.get(url)\n",
    "\n",
    "\n",
    "- Import the Beautiful soup functions to parse the data returned from the website\n",
    "\n",
    "      from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "- Parse the html in the 'page' variable and store it in BeautifulSoup format\n",
    "\n",
    "      soup = BeautifulSoup(page) / BeautifulSoup(page.text, 'html.parser')\n",
    "\n",
    "\n",
    "#### 2. BeautifulSoup 的屬性和方法:\n",
    "\n",
    "- soup.prettify(): 查看 HTML 的結構\n",
    "\n",
    "\n",
    "- soup.tag: 回傳 tag 的內容(包含 tag)\n",
    "\n",
    "\n",
    "- soup.tag.string: 回傳 tag 內的字串\n",
    "\n",
    "\n",
    "- soup.find(\"tag\"): 尋找第一個 tag\n",
    "\n",
    "\n",
    "- soup.find_all(\"tag\"): 尋找所有的 tag\n",
    "\n",
    "\n",
    "- soup.find_all([\"title\", \"a\"]): 尋找多個的 tag\n",
    "\n",
    "\n",
    "- soup.find / soup.find_all(\"標籤名稱\", {\"屬性名稱\": \"屬性內容\"}): 尋找指定標籤中符合屬性條件的內容\n",
    "\n",
    "\n",
    "- soup.select(\"#id or .classname\"): 回傳指定的 CSS selector\n",
    "\n",
    "\n",
    "- soup.select(\"html head title\"): 逐層尋找 title 內容\n",
    "\n",
    "\n",
    "- soup.select(\"div img\")[0][\"src\"]: 多層過濾取得屬性內容\n",
    "\n",
    "\n",
    "- 取得標籤的屬性內容:\n",
    "\n",
    "      回傳值.get(\"屬性名稱\") or 回傳值[\"屬性名稱\"]\n",
    "        \n",
    "      Example: .get('href'): 回傳所有的連結名稱\n",
    "\n",
    "\n",
    "- .find(text=True): 取得 tag 內的內文\n",
    "\n",
    "\n",
    "### 五、瀏覽器的自動化操作 - Selenium\n",
    "\n",
    "#### 1. 安裝 Selenium\n",
    "\n",
    "    pip install selenium\n",
    "\n",
    "#### 2. 下載驅動程式 Chrome WebDriver，將 ChromeDriver.exe 複製到開發專案的目錄中\n",
    "\n",
    "    https://site.google.com/a/chromium.org/chromedriver/downloads\n",
    "\n",
    "#### 3. 建立 google chrome 瀏覽器物件\n",
    "\n",
    "    from selenium import webdriver\n",
    "    driver = webdriver.Chrome()\n",
    "    \n",
    "#### 4. Webdriver 的屬性和方法:\n",
    "\n",
    "- .current_url: 取得目前的網址\n",
    "\n",
    "\n",
    "- .get('url'): 連結 url 網址\n",
    "\n",
    "\n",
    "- .page_source: 讀取網頁原始碼\n",
    "\n",
    "\n",
    "- .text: 讀取元素內容\n",
    "\n",
    "\n",
    "- .size: 回傳元素大小\n",
    "\n",
    "\n",
    "- .get_window_position(): 取得視窗左上角的位置\n",
    "\n",
    "\n",
    "- .set_window_position(x, y): 設定視窗左上角的位置\n",
    "\n",
    "\n",
    "- .get_window_size(): 取得視窗的高度和寬度\n",
    "\n",
    "\n",
    "- .set_window_size(x, y): 設定視窗的高度和寬度\n",
    "\n",
    "\n",
    "- .maximize_window(): 瀏覽器視窗最大化\n",
    "\n",
    "\n",
    "- .click(): 按點擊紐\n",
    "\n",
    "\n",
    "- .send_keys(): 用鍵盤輸入\n",
    "\n",
    "\n",
    "- .submit(): 提交\n",
    "\n",
    "\n",
    "- .clear(): 清除輸入內容\n",
    "\n",
    "\n",
    "- .back(): 返回上一頁\n",
    "\n",
    "\n",
    "- .forward(): 進入下一頁\n",
    "\n",
    "\n",
    "- .refresh(): 重新整理頁面\n",
    "\n",
    "\n",
    "- .close(): 關閉瀏覽器\n",
    "\n",
    "\n",
    "- .quit(): 關閉瀏覽器並退出驅動程序\n",
    "\n",
    "\n",
    "#### 5. 收尋網頁元素\n",
    "\n",
    "- find_element_by_id('id'): 以 id 查詢符合的玩素\n",
    "\n",
    "\n",
    "- find_element_by_class_name('class name'): 以類別名稱查詢符合的玩素\n",
    "\n",
    "\n",
    "- find_element_by_tag_name('tag name'): 以 HTML 標籤查詢符合的玩素\n",
    "\n",
    "\n",
    "- find_element_by_name('name'): 以名稱查詢符合的玩素\n",
    "\n",
    "\n",
    "- find_element_by_link_text('text'): 以連結文字查詢符合的玩素\n",
    "\n",
    "\n",
    "- find_element_by_partial_link_text('text'): 以部分連結文字查詢符合的玩素\n",
    "\n",
    "\n",
    "- find_element_by_css_selector('selector'): 以 CSS 選擇器查詢符合的玩素\n",
    "\n",
    "\n",
    "- find_element_by_xpath(): 以 xml 的路徑(xpath)查詢與每個 node 的特性來找尋玩素\n",
    "\n",
    "\n",
    "#### 6. 取消 Alert 彈出式視窗的設定\n",
    "\n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    \n",
    "    prefs = {\"profile.default_content_setting_values.notifications\": 2}\n",
    "    \n",
    "    chrome_options.add_experimental_option(\"prefs\": prefs)\n",
    "    \n",
    "    driver = webdriver.Chrome(chrome_options=chrome_options)\n",
    "\n",
    "\n",
    "### References: \n",
    "\n",
    "- [Beginner’s guide to Web Scraping in Python using BeautifulSoup](https://www.analyticsvidhya.com/blog/2015/10/beginner-guide-web-scraping-beautiful-soup-python/#)\n",
    "\n",
    "\n",
    "- [Beautiful Soup Basic HTML Scraping](https://chrisalbon.com/python/web_scraping/beautiful_soup_html_basics/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
